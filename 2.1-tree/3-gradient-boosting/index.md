---
layout: page

parent_id: 2.1-tree
id: 3-gradient-boosting
title: ðŸŒ³ Gradient Boosting

notebook: notebook-adult-dataset.ipynb
---



# Gradient Boosting (GBM)

In theory are just as fast to train as random forests, but in practice you will have to try lots of different hyperparameters. They can overfit. At inference time they will be less fast, because they cannot operate in parallel. But they are often a little bit more accurate than random forests.

<p align="center"><img width="100%" src="../img/GB.png" /></p>

<p align="center"><img width="50%" src="../img/GradientBoosting.png" /></p>


