{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: We need preprocessed texts (tokinized and numericalized) in this notebook\n",
    "\n",
    "> Notebook based on:\n",
    "> 1. https://github.com/fastai/course-v3/blob/master/nbs/dl2/12_text.ipynb\n",
    "> 2. https://github.com/fastai/course-v3/blob/master/nbs/dl2/12a_awd_lstm.ipynb\n",
    "> 3. https://github.com/fastai/course-v3/blob/master/nbs/dl2/12b_lm_pretrain.ipynb\n",
    "> 4. https://github.com/fastai/course-v3/blob/master/nbs/dl2/12c_ulmfit.ipynb\n",
    "> \n",
    "> Video:\n",
    "> - https://youtu.be/vnOpEwmtFJ8?t=4687 from 1:18:00 to 2:08:00 (50 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BPTT_LEN   = 70 # Lengh of the minisequences in the big stream (used In Dataset)\n",
    "BATCH_SIZE = 64 # (used In DataLoader)\n",
    "PAD_TOKEN  = 1  # Number for xxPad token (used in the nn.Embedding layer of the Model)\n",
    "VOCAB_LEN  = None # This will be updated when we read the vocab.pkl file (used in the nn.Embedding layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch: 1.8.1\n",
      "Fast.ai: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "\n",
    "import fastai\n",
    "print(\"Pytorch:\", torch.__version__)\n",
    "print(\"Fast.ai:\", fastai.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  train  unsup  vocab.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"../../Datasets/NLP/IMBd_prepro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg  pos\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"../../Datasets/NLP/IMBd_prepro/train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = open(\"../../Datasets/NLP/IMBd_prepro/vocab.pkl\",'rb')\n",
    "vocab = pickle.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65539"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_LEN = len(vocab)\n",
    "VOCAB_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denumericalize(list_of_nums):\n",
    "    return [vocab[i] for i in list_of_nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'xxup',\n",
       " 'xxmaj',\n",
       " 'the',\n",
       " '.',\n",
       " ',',\n",
       " 'and',\n",
       " 'a',\n",
       " 'of',\n",
       " 'to',\n",
       " 'is',\n",
       " 'it',\n",
       " 'in',\n",
       " 'i',\n",
       " 'this']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denumericalize( range(20) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def parallel_map(func, array):\n",
    "    \n",
    "    cpu_cores = multiprocessing.cpu_count()\n",
    "    array_len = len(array)\n",
    "    chunksize = array_len // 100\n",
    "    \n",
    "    if cpu_cores<2:\n",
    "        return list(tqdm(map(func, arr), total=array_len))\n",
    "    else:\n",
    "        with ProcessPoolExecutor(max_workers=cpu_cores) as ex:\n",
    "            return list(tqdm(ex.map(func, array, chunksize=chunksize), total=array_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <center> Dataset & Dataloader for Langauge Model\n",
    "- X: Text\n",
    "- Y: Same text but shifted by 1 token\n",
    "\n",
    "At every epoch:\n",
    "\n",
    "1. **Shuffle** (sort randomly) our collection of texts.\n",
    "2. **Concatenate** the individual texts together into a big stream. \n",
    "3. **Cut** this stream into a certain number of batches (which is our batch size).\n",
    "   - For instance, if the stream has 50,000 tokens and we set a batch size of 10, this will give us 10 mini-streams of 5,000 tokens.\n",
    "   \n",
    "So to recap, at every epoch we shuffle our collection of documents and concatenate them into a stream of tokens. We then cut that stream into a batch of fixed-size consecutive mini-streams. Our model will then read the mini-streams in order, and thanks to an inner state, it will produce the same activation whatever sequence length we picked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, prepro_texts_dir, bptt=70, shuffle=False):\n",
    "        \n",
    "        # Read tokenized and numeralized text files (numpy format)\n",
    "        np_filepaths = list( pathlib.Path(prepro_texts_dir).glob('**/*.npy') ) \n",
    "        \n",
    "        # Open numpy arrays in parallel\n",
    "        #self.texts_np = list(map(func=np.load, np_filepaths))  # Non parallel version   \n",
    "        self.texts_np = parallel_map(func=np.load, array=np_filepaths)\n",
    "\n",
    "        self.bptt    = bptt\n",
    "        self.shuffle = shuffle\n",
    "        self.total_tokens = sum([len(t) for t in self.texts_np])\n",
    "        \n",
    "        self.concat_texts_into_stream()\n",
    "        \n",
    "    # this is necesseary at the begining of every epoch for train !!!!\n",
    "    def concat_texts_into_stream(self):\n",
    "        \n",
    "        # 1. Reorder texts if we need to\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.texts_np)\n",
    "            #self.texts_np = self.texts_np[np.random.permutation(len(self.texts_np))]\n",
    "            \n",
    "        # 2. Concat texts into a large stream\n",
    "        self.stream = np.concatenate(self.texts_np)\n",
    "        #self.stream = torch.cat([torch.Tensor(t) for t in self.texts_np])\n",
    "                \n",
    "    def __len__(self):\n",
    "        return self.total_tokens // self.bptt\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.stream[idx   : idx+self.bptt]\n",
    "        y = self.stream[idx+1 : idx+self.bptt+1] # shifted by 1\n",
    "        \n",
    "        # convert from numpy.uint16 to torch.int64        \n",
    "        x = torch.tensor(x.astype(\"int64\"))\n",
    "        y = torch.tensor(y.astype(\"int64\"))\n",
    "        \n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47366e87206540558b19e485cd9c5490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db25c2fa9de402391f43ebf6f2dceb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = LM_Dataset(\"../../Datasets/NLP/IMBd_prepro/train\", bptt=BPTT_LEN, shuffle=True)\n",
    "valid_ds = LM_Dataset(\"../../Datasets/NLP/IMBd_prepro/test\",  bptt=BPTT_LEN, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   7,  655,  176, 1541,   13,  573, 7717,   12, 2874,   28,    8,  389,\n",
       "          734,   10,  109,   78,   19,  391,  123,   42,  819,   72,   14, 1328,\n",
       "           11,  114,   16,  237,  214,   14, 2081,   12,  183,  327,  153, 8143,\n",
       "         1880,   51,   57, 1051,  327,    9,    7,   17,   77,  684,   10,   79,\n",
       "         1724,   25, 3566,    9,   12,  225,   84,   28,  210,  439,   10, 1828,\n",
       "           23, 2134,   10, 2134,   10,   11,   79,  724,    9,  601]),\n",
       " tensor([ 655,  176, 1541,   13,  573, 7717,   12, 2874,   28,    8,  389,  734,\n",
       "           10,  109,   78,   19,  391,  123,   42,  819,   72,   14, 1328,   11,\n",
       "          114,   16,  237,  214,   14, 2081,   12,  183,  327,  153, 8143, 1880,\n",
       "           51,   57, 1051,  327,    9,    7,   17,   77,  684,   10,   79, 1724,\n",
       "           25, 3566,    9,   12,  225,   84,   28,  210,  439,   10, 1828,   23,\n",
       "         2134,   10, 2134,   10,   11,   79,  724,    9,  601,   54]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('xxbos xxmaj taking old collection of stories poses a challenge for the production team , how can this classic character be brought up to date and make it interesting enough to capture a new audience while stirring memories from her former audience . xxmaj in my opinion , their mission was accomplished . a must see for young children , pre - teens , teens , and their parents .',\n",
       " 'xxmaj taking old collection of stories poses a challenge for the production team , how can this classic character be brought up to date and make it interesting enough to capture a new audience while stirring memories from her former audience . xxmaj in my opinion , their mission was accomplished . a must see for young children , pre - teens , teens , and their parents . ok')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(denumericalize(train_ds[0][0])), \" \".join(denumericalize(train_ds[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader (with custom sampler for BPTT)\n",
    "\n",
    "if we divide our big stream of **28 elements** with **batch_size of 5**:\n",
    "\n",
    "|               |              |               |               |               |               |\n",
    "|---------------|--------------|---------------|---------------|---------------|---------------|\n",
    "| **1st batch** | stream_idx 0 | stream_idx 6  | stream_idx 12 | stream_idx 18 | stream_idx 23 |\n",
    "| **2nd batch** | stream_idx 1 | stream_idx 7  | stream_idx 13 | stream_idx 19 | stream_idx 24 |\n",
    "| **3rd batch** | stream_idx 2 | stream_idx 8  | stream_idx 14 | stream_idx 20 | stream_idx 25 |\n",
    "| **4th batch** | stream_idx 3 | stream_idx 8  | stream_idx 15 | stream_idx 21 | stream_idx 26 |\n",
    "| **5th batch** | stream_idx 4 | stream_idx 10 | stream_idx 16 | stream_idx 22 | stream_idx 27 |\n",
    "| **6th batch** | stream_idx 5 | stream_idx 11 | stream_idx 17 |               |               |\n",
    "\n",
    "https://pytorchnlp.readthedocs.io/en/latest/_modules/torchnlp/samplers/bptt_sampler.html\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPTT_BatchSampler(Sampler):\n",
    "    def __init__(self, n_elements, batch_size, drop_last):\n",
    "        \n",
    "        indexes = np.array_split(list(range(n_elements)), batch_size) # magic happens here\n",
    "        \n",
    "        n_batches = n_elements//batch_size\n",
    "        self.batches_idxs = np.array([x[:n_batches] for x in indexes]).T.tolist()\n",
    "        \n",
    "        if not drop_last:\n",
    "            last_batch_idxs = np.array([x[n_batches:] for x in indexes if x[n_batches:].size==1]).T.tolist()\n",
    "            self.batches_idxs += last_batch_idxs\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return iter(self.batches_idxs)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.batches_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,\n",
       " [[0, 6, 12, 18, 23],\n",
       "  [1, 7, 13, 19, 24],\n",
       "  [2, 8, 14, 20, 25],\n",
       "  [3, 9, 15, 21, 26],\n",
       "  [4, 10, 16, 22, 27],\n",
       "  [5, 11, 17]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = BPTT_BatchSampler(n_elements=28, batch_size=5, drop_last=False)\n",
    "len(s), list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " [[0, 6, 12, 18, 23],\n",
       "  [1, 7, 13, 19, 24],\n",
       "  [2, 8, 14, 20, 25],\n",
       "  [3, 9, 15, 21, 26],\n",
       "  [4, 10, 16, 22, 27]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = BPTT_BatchSampler(n_elements=28, batch_size=5, drop_last=True)\n",
    "len(s), list(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 70]), torch.Size([64, 70]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DataLoader(train_ds, batch_sampler=BPTT_BatchSampler(n_elements=len(train_ds),\n",
    "                                                                batch_size=BATCH_SIZE,\n",
    "                                                                drop_last=True))\n",
    "\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=BPTT_BatchSampler(n_elements=len(valid_ds),\n",
    "                                                                batch_size=BATCH_SIZE,\n",
    "                                                                drop_last=True))\n",
    "\n",
    "batch_x, batch_y = next(iter(train_dl))\n",
    "batch_x.shape, batch_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "     \n",
    "    def __init__(self, vocab_sz, emb_dim, hidden_dim, n_layers):\n",
    "        super().__init__()\n",
    "                \n",
    "        # Embeding\n",
    "        self.emb    = nn.Embedding(vocab_sz, emb_dim, padding_idx=PAD_TOKEN)\n",
    "        emb_init_range = 0.1\n",
    "        self.emb.weight.data.uniform_(-emb_init_range, emb_init_range)\n",
    "        \n",
    "        # LSTMs\n",
    "        self.lstm = nn.LSTM(input_size  = emb_dim,\n",
    "                            hidden_size = hidden_dim,\n",
    "                            num_layers  = n_layers,\n",
    "                            batch_first = True)\n",
    "        self.in_hidden = [torch.zeros(n_layers, BATCH_SIZE, hidden_dim) for _ in range(2)] # Initial hidden state\n",
    "        \n",
    "        # Linear\n",
    "        self.head = nn.Linear(in_features=hidden_dim, out_features=vocab_sz, bias=True)\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        out = self.emb(input_seq)\n",
    "        out, out_hidden = self.lstm(out, self.in_hidden)\n",
    "        out = self.head(out)\n",
    "        \n",
    "        self.in_hidden = [h.detach() for h in out_hidden] # Truncated BPTT\n",
    "        return out\n",
    "    \n",
    "    def reset(self):\n",
    "        for h in self.in_hidden: h.zero_()\n",
    "            \n",
    "    # Move initial hidden state to CUDA when model.to(device)\n",
    "    def to(self, *args, **kwargs):\n",
    "        self = super().to(*args, **kwargs)\n",
    "        self.in_hidden = [h.to(*args, **kwargs) for h in self.in_hidden]\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 70, 65539])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model\n",
    "model = SimpleLSTM(vocab_sz=VOCAB_LEN, emb_dim=300, hidden_dim=700, n_layers=2)\n",
    "#tst_input = torch.randint(low=0,high=100, size=(64,70))\n",
    "\n",
    "batch_p = model(batch_x) # prediction\n",
    "batch_p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss: Flat CrossEntropy\n",
    "\n",
    "Custom CrossEntropyLossFlat inspired by [Fast.ai CrossEntropyLossFlat()](https://docs.fast.ai/losses.html#CrossEntropyLossFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred:   torch.Size([64, 70, 65539])\n",
      "Target: torch.Size([64, 70])\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred:  \", batch_p.shape)\n",
    "print(\"Target:\", batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred:   torch.Size([4480, 65539])\n",
      "Target: torch.Size([4480])\n"
     ]
    }
   ],
   "source": [
    "batch_p_flatten = batch_p.view(-1, batch_p.shape[-1])\n",
    "batch_y_flatten = batch_y.view(-1)\n",
    "\n",
    "print(\"Pred:  \", batch_p_flatten.shape)\n",
    "print(\"Target:\", batch_y_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLossFlat(nn.Module):\n",
    "    \"\"\"Flatten version of nn.CrossEntropyLoss()\"\"\"\n",
    "    def forward(self, pred, target):\n",
    "        pred_flatten   = pred.view(-1, pred.shape[-1])\n",
    "        target_flatten = target.view(-1)\n",
    "        return F.cross_entropy(pred_flatten, target_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.0937, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "ce_loss(batch_p_flatten, batch_y_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.0937, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_flat_loss = CrossEntropyLossFlat()\n",
    "ce_flat_loss(batch_p, batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fastai.text.all import *\n",
    "from fastai.learner           import Learner\n",
    "from fastai.data.core         import DataLoaders\n",
    "from fastai.metrics           import accuracy, Perplexity\n",
    "\n",
    "from fastai.callback.all import * # For lr_find() and fit_one_cycle()\n",
    "from fastai.callback.core     import Callback\n",
    "#from fastai.callback.data     import CudaCallback\n",
    "from fastai.callback.progress import ProgressCallback, ShowGraphCallback\n",
    "from fastai.callback.training import GradientClip\n",
    "from fastai.callback.rnn      import ModelResetter, RNNCallback, RNNRegularizer\n",
    "from fastai.callback.tracker  import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowGraphEveryBatchCallback(Callback):\n",
    "    \"Update a graph of training and validation loss\"\n",
    "        \n",
    "    def after_batch(self):\n",
    "        if self.iter%15 == 0:\n",
    "            rec   = self.learn.recorder\n",
    "            iters = range(len(rec.losses))\n",
    "            x_bounds = (0, self.n_epoch * self.n_iter)\n",
    "            y_bounds = (0, 10)\n",
    "            self.progress.mbar.update_graph([(iters, rec.losses)], x_bounds, y_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls       = DataLoaders(train_dl, valid_dl),\n",
    "                model     = SimpleLSTM(vocab_sz=VOCAB_LEN, emb_dim=300, hidden_dim=700, n_layers=2), \n",
    "                loss_func = CrossEntropyLossFlat(),\n",
    "                metrics   = [accuracy, Perplexity],\n",
    "                cbs       = [\n",
    "                          #  TrainEvalCallback, # By default\n",
    "                          #  Recorder,          # By default\n",
    "                          #  ProgressCallback,  # By default\n",
    "                             ModelResetter,\n",
    "                             ShowGraphEveryBatchCallback,\n",
    "                             GradientClip(max_norm=0.1),\n",
    "                          #  TensorBoardCallback(\"/home/javi/Escritorio/tensorboard\", trace_model=True)\n",
    "                          #  partial(AvgStatsCallback,accuracy_flat),\n",
    "                          #  Recorder,  #     Registers statistics (lr, loss and metrics) during training\n",
    "                          #  partial(GradientClipping, clip=0.1),\n",
    "                          #  partial(RNNTrainer, α=2., β=1.),\n",
    "                          #  ParamScheduler({'lr': SchedLin(1e-3, 1e-2)})\n",
    "                          #  EarlyStoppingCallback(patience=3)\n",
    "                          #  SaveModelCallback()\n",
    "                            ])\n",
    "#learn.show_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='75' class='' max='1680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      4.46% [75/1680 00:19<06:47 9.8712]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-fa2b36ab6009>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#fig = learn.recorder.plot(suggestion=True, return_fig=True);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#lr  = learn.recorder.min_grad_lr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggestions)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mcb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshow_plot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_lr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msuggestions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelStepException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD8CAYAAABuHP8oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPU0lEQVR4nO3daYxd5X3H8e+/HoMXjGwPAzU2qk2VmE3IwEBNTCOXJK0xFJCoEFFdkTaV1UqlTrpEjpBK01eERC1FLUGGOF2gRhFLSRFtWRp3EeB0bEzijRqDgwfcMHFllsgGQ/59cY9hPMx6t7kPfD/SaM4595x7fnc89+dzn3vO3MhMJEnl+ZnJDiBJqo8FLkmFssAlqVAWuCQVygKXpEJZ4JJUqDELPCLWR8SrEbFt0LK5EfFYROyuvs9pbUxJ0lDjOQL/G2DFkGVrgScy82PAE9W8JKmNYjwX8kTEQuDhzDynmn8OWJ6Z+yNiHrAxMxe3NKkk6RhddW53SmbuB6hK/OSRVoyI1cBqgJkzZ15wxhln1LlLSfpo2rx5848zs2fo8noLfNwycx2wDqC3tzf7+vpavUtJ+lCJiB8Ot7zes1B+VA2dUH1/td5gkqT61Fvg3wGur6avBx5qThxJ0niN5zTCDcBTwOKI6I+IzwM3A5+JiN3AZ6p5SVIbjTkGnpmfHeGmTzU5iyR9wJEjR+jv7+fw4cOTHaXlpk2bxoIFC5g6deq41m/5m5iS1Ij+/n5mzZrFwoULiYjJjtMymcmBAwfo7+9n0aJF49rGS+kldbTDhw/T3d39oS5vgIigu7t7Qq80LHBJHe/DXt5HTfRxWuCSVCgLXJLGcPDgQW6//fYJb7dy5UoOHjzY/EAVC1ySxjBSgb/77rujbvfII48we/bsFqXyLBRJGtPatWvZs2cPS5YsYerUqZxwwgnMmzePrVu3smPHDq6++mr27dvH4cOHWbNmDatXrwZg4cKF9PX18eabb3LZZZdxySWX8OSTTzJ//nweeughpk+f3lAuC1xSMb7yT9vZ8crrTb3Ps049kZt+9exR17n55pvZtm0bW7duZePGjVx++eVs27btvdP91q9fz9y5czl06BAXXngh11xzDd3d3cfcx+7du9mwYQN33nkn1157Lffffz+rVq1qKLsFLkkTdNFFFx1zrvZtt93Ggw8+CMC+ffvYvXv3Bwp80aJFLFmyBIALLriAvXv3NpzDApdUjLGOlNtl5syZ701v3LiRxx9/nKeeeooZM2awfPnyYc/lPv7449+bnjJlCocOHWo4h29iStIYZs2axRtvvDHsba+99hpz5sxhxowZ7Nq1i6effrptuTwCl6QxdHd3s2zZMs455xymT5/OKaec8t5tK1as4I477uDcc89l8eLFLF26tG25xvWRas3iBzpImqidO3dy5plnTnaMthnu8UbE5szsHbquQyiSVCgLXJIKZYFL6njtHOqdTBN9nBa4pI42bdo0Dhw48KEv8aN/D3zatGnj3sazUCR1tAULFtDf38/AwMBkR2m5o5/IM14WuKSONnXq1HF/Qs1HjUMoklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFcoCl6RCNVTgEfHFiNgeEdsiYkNEjP+zgCRJDam7wCNiPvD7QG9mngNMAa5rVjBJ0ugaHULpAqZHRBcwA3il8UiSpPGou8Az82Xg68BLwH7gtcx8dOh6EbE6Ivoiou+j8KGkktQujQyhzAGuAhYBpwIzI2LV0PUyc11m9mZmb09PT/1JJUnHaGQI5dPAi5k5kJlHgAeATzQnliRpLI0U+EvA0oiYEREBfArY2ZxYkqSxNDIGvgm4D9gC/KC6r3VNyiVJGkNXIxtn5k3ATU3KIkmaAK/ElKRCWeCSVCgLXJIKZYFLUqEscEkqlAUuSYWywCWpUBa4JBXKApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFcoCl6RCWeCSVCgLXJIKZYFLUqEscEkqlAUuSYWywCWpUBa4JBXKApekQlngklSohgo8ImZHxH0RsSsidkbExc0KJkkaXVeD2/8l8C+Z+WsRcRwwowmZJEnjUHeBR8SJwCeBzwFk5tvA282JJUkaSyNDKKcDA8C3IuKZiLgrImYOXSkiVkdEX0T0DQwMNLA7SdJgjRR4F3A+8I3MPA/4CbB26EqZuS4zezOzt6enp4HdSZIGa6TA+4H+zNxUzd9HrdAlSW1Qd4Fn5v8C+yJicbXoU8COpqSSJI2p0bNQbgDuqc5AeQH4zcYjSZLGo6ECz8ytQG9zokiSJsIrMSWpUBa4JBXKApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFcoCl6RCWeCSVCgLXJIKZYFLUqEscEkqlAUuSYWywCWpUBa4JBXKApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpEI1XOARMSUinomIh5sRSJI0Ps04Al8D7GzC/UiSJqChAo+IBcDlwF3NiSNJGq9Gj8BvBb4E/HSkFSJidUT0RUTfwMBAg7uTJB1Vd4FHxBXAq5m5ebT1MnNdZvZmZm9PT0+9u5MkDdHIEfgy4MqI2AvcC1waEXc3JZUkaUx1F3hmfjkzF2TmQuA64N8yc1XTkkmSRuV54JJUqK5m3ElmbgQ2NuO+JEnj4xG4JBXKApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFcoCl6RCWeCSVCgLXJIKZYFLUqEscEkqlAUuSYWywCWpUBa4JBXKApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpELVXeARcVpEfDcidkbE9ohY08xgkqTRdTWw7TvAH2bmloiYBWyOiMcyc0eTskmSRlH3EXhm7s/MLdX0G8BOYH6zgkmSRteUMfCIWAicB2wa5rbVEdEXEX0DAwPN2J0kiSYUeEScANwPfCEzXx96e2auy8zezOzt6elpdHeSpEpDBR4RU6mV9z2Z+UBzIkmSxqORs1AC+CawMzP/vHmRJEnj0cgR+DLgN4BLI2Jr9bWySbkkSWOo+zTCzPwvIJqYRZI0AV6JKUmFssAlqVAWuCQVygKXpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFcoCl6RCWeCSVCgLXJIKZYFLUqEscEkqlAUuSYWywCWpUBa4JBXKApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFaqhAo+IFRHxXEQ8HxFrmxVKkjS2ugs8IqYAfw1cBpwFfDYizmpWMEnS6Bo5Ar8IeD4zX8jMt4F7gauaE0uSNJauBradD+wbNN8P/MLQlSJiNbC6mn0rIrY1sM9WOwn48WSHGIX56tfJ2cB8jfqw5/u54RY2UuAxzLL8wILMdcA6gIjoy8zeBvbZUuZrTCfn6+RsYL5GfVTzNTKE0g+cNmh+AfBKY3EkSePVSIH/N/CxiFgUEccB1wHfaU4sSdJY6h5Cycx3IuL3gH8FpgDrM3P7GJutq3d/bWK+xnRyvk7OBuZr1EcyX2R+YNhaklQAr8SUpEJZ4JJUqLYUeCdcch8Rp0XEdyNiZ0Rsj4g11fK5EfFYROyuvs8ZtM2Xq8zPRcSvtCnnlIh4JiIe7rR8ETE7Iu6LiF3Vz/HiTskXEV+s/l23RcSGiJg22dkiYn1EvDr42od6MkXEBRHxg+q22yJiuFN4m5Hta9W/7fcj4sGImD0Z2UbKN+i2P4qIjIiTOi1fRNxQZdgeEbe0PF9mtvSL2huce4DTgeOAZ4GzWr3fYXLMA86vpmcB/0PtTwDcAqytlq8FvlpNn1VlPR5YVD2GKW3I+QfAPwAPV/Mdkw/4W+C3q+njgNmdkI/aRWUvAtOr+W8Dn5vsbMAngfOBbYOWTTgT8D3gYmrXXvwzcFmLsv0y0FVNf3Wyso2Ur1p+GrUTJ34InNRJ+YBfAh4Hjq/mT251vnYcgXfEJfeZuT8zt1TTbwA7qT3xr6JWTFTfr66mrwLuzcy3MvNF4Hlqj6VlImIBcDlw16DFHZEvIk6k9kv7TYDMfDszD3ZKPmpnVE2PiC5gBrVrEiY1W2b+B/B/QxZPKFNEzANOzMynsvaM/7tB2zQ1W2Y+mpnvVLNPU7u2o+3ZRspX+QvgSxx70WCn5Ptd4ObMfKta59VW52tHgQ93yf38Nux3RBGxEDgP2ASckpn7oVbywMnVapOR+1Zqv5w/HbSsU/KdDgwA36qGeO6KiJmdkC8zXwa+DrwE7Adey8xHOyHbMCaaaX41PXR5q/0WtSPCjskWEVcCL2fms0Nu6oh8wMeBX4yITRHx7xFxYavztaPAx3XJfbtExAnA/cAXMvP10VYdZlnLckfEFcCrmbl5vJsMs6yVP9cuai8Zv5GZ5wE/oTYEMJK25avGka+i9vL0VGBmRKzqhGwTMFKmtmeNiBuBd4B7ji4aIUM7/41nADcCfzLczSPkmIznyBxgKfDHwLerMe2W5WtHgXfMJfcRMZVaed+TmQ9Ui39UvZSh+n70ZU+7cy8DroyIvdSGmS6NiLs7KF8/0J+Zm6r5+6gVeifk+zTwYmYOZOYR4AHgEx2SbaiJZurn/aGMwctbIiKuB64Afr16Wd8p2X6e2n/Qz1bPkQXAloj42Q7JR7W/B7Lme9ReSZ/U0nzNGNAfY7C/C3iB2g//6JuYZ7d6v8PkCGpjTLcOWf41jn1T6ZZq+myOfePhBdrwJma17+W8/yZmx+QD/hNYXE3/aZVt0vNR+yuY26mNfQe1seUbOiTbQo59o2vCmaj92YqlvP9G18oWZVsB7AB6hqzX9mzD5Rty217efxOzI/IBvwP8WTX9cWrDJtHKfE3/hR3hga6kdtbHHuDGduxzmAyXUHt58n1ga/W1EugGngB2V9/nDtrmxirzczTp3etxZl3O+wXeMfmAJUBf9TP8R2ovFzsiH/AVYBewDfj76skyqdmADdTG5I9QO9r6fD2ZgN7qce0B/orqCuoWZHu+Kp2jz487JiPbSPmG3L6XqsA7JR+1A9S7q/1tAS5tdT4vpZekQnklpiQVygKXpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5Jhfp/y7IlHkW4+9kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "#fig = learn.recorder.plot(suggestion=True, return_fig=True);\n",
    "#lr  = learn.recorder.min_grad_lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='27' class='' max='1680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.61% [27/1680 00:06<06:57 23.6346]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3ea49add0339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    110\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[1;32m    111\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelStepException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD8CAYAAABuHP8oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPU0lEQVR4nO3daYxd5X3H8e+/HoMXjGwPAzU2qk2VmE3IwEBNTCOXJK0xFJCoEFFdkTaV1UqlTrpEjpBK01eERC1FLUGGOF2gRhFLSRFtWRp3EeB0bEzijRqDgwfcMHFllsgGQ/59cY9hPMx6t7kPfD/SaM4595x7fnc89+dzn3vO3MhMJEnl+ZnJDiBJqo8FLkmFssAlqVAWuCQVygKXpEJZ4JJUqDELPCLWR8SrEbFt0LK5EfFYROyuvs9pbUxJ0lDjOQL/G2DFkGVrgScy82PAE9W8JKmNYjwX8kTEQuDhzDynmn8OWJ6Z+yNiHrAxMxe3NKkk6RhddW53SmbuB6hK/OSRVoyI1cBqgJkzZ15wxhln1LlLSfpo2rx5848zs2fo8noLfNwycx2wDqC3tzf7+vpavUtJ+lCJiB8Ot7zes1B+VA2dUH1/td5gkqT61Fvg3wGur6avBx5qThxJ0niN5zTCDcBTwOKI6I+IzwM3A5+JiN3AZ6p5SVIbjTkGnpmfHeGmTzU5iyR9wJEjR+jv7+fw4cOTHaXlpk2bxoIFC5g6deq41m/5m5iS1Ij+/n5mzZrFwoULiYjJjtMymcmBAwfo7+9n0aJF49rGS+kldbTDhw/T3d39oS5vgIigu7t7Qq80LHBJHe/DXt5HTfRxWuCSVCgLXJLGcPDgQW6//fYJb7dy5UoOHjzY/EAVC1ySxjBSgb/77rujbvfII48we/bsFqXyLBRJGtPatWvZs2cPS5YsYerUqZxwwgnMmzePrVu3smPHDq6++mr27dvH4cOHWbNmDatXrwZg4cKF9PX18eabb3LZZZdxySWX8OSTTzJ//nweeughpk+f3lAuC1xSMb7yT9vZ8crrTb3Ps049kZt+9exR17n55pvZtm0bW7duZePGjVx++eVs27btvdP91q9fz9y5czl06BAXXngh11xzDd3d3cfcx+7du9mwYQN33nkn1157Lffffz+rVq1qKLsFLkkTdNFFFx1zrvZtt93Ggw8+CMC+ffvYvXv3Bwp80aJFLFmyBIALLriAvXv3NpzDApdUjLGOlNtl5syZ701v3LiRxx9/nKeeeooZM2awfPnyYc/lPv7449+bnjJlCocOHWo4h29iStIYZs2axRtvvDHsba+99hpz5sxhxowZ7Nq1i6effrptuTwCl6QxdHd3s2zZMs455xymT5/OKaec8t5tK1as4I477uDcc89l8eLFLF26tG25xvWRas3iBzpImqidO3dy5plnTnaMthnu8UbE5szsHbquQyiSVCgLXJIKZYFL6njtHOqdTBN9nBa4pI42bdo0Dhw48KEv8aN/D3zatGnj3sazUCR1tAULFtDf38/AwMBkR2m5o5/IM14WuKSONnXq1HF/Qs1HjUMoklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFcoCl6RCNVTgEfHFiNgeEdsiYkNEjP+zgCRJDam7wCNiPvD7QG9mngNMAa5rVjBJ0ugaHULpAqZHRBcwA3il8UiSpPGou8Az82Xg68BLwH7gtcx8dOh6EbE6Ivoiou+j8KGkktQujQyhzAGuAhYBpwIzI2LV0PUyc11m9mZmb09PT/1JJUnHaGQI5dPAi5k5kJlHgAeATzQnliRpLI0U+EvA0oiYEREBfArY2ZxYkqSxNDIGvgm4D9gC/KC6r3VNyiVJGkNXIxtn5k3ATU3KIkmaAK/ElKRCWeCSVCgLXJIKZYFLUqEscEkqlAUuSYWywCWpUBa4JBXKApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFcoCl6RCWeCSVCgLXJIKZYFLUqEscEkqlAUuSYWywCWpUBa4JBXKApekQlngklSohgo8ImZHxH0RsSsidkbExc0KJkkaXVeD2/8l8C+Z+WsRcRwwowmZJEnjUHeBR8SJwCeBzwFk5tvA282JJUkaSyNDKKcDA8C3IuKZiLgrImYOXSkiVkdEX0T0DQwMNLA7SdJgjRR4F3A+8I3MPA/4CbB26EqZuS4zezOzt6enp4HdSZIGa6TA+4H+zNxUzd9HrdAlSW1Qd4Fn5v8C+yJicbXoU8COpqSSJI2p0bNQbgDuqc5AeQH4zcYjSZLGo6ECz8ytQG9zokiSJsIrMSWpUBa4JBXKApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFcoCl6RCWeCSVCgLXJIKZYFLUqEscEkqlAUuSYWywCWpUBa4JBXKApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpEI1XOARMSUinomIh5sRSJI0Ps04Al8D7GzC/UiSJqChAo+IBcDlwF3NiSNJGq9Gj8BvBb4E/HSkFSJidUT0RUTfwMBAg7uTJB1Vd4FHxBXAq5m5ebT1MnNdZvZmZm9PT0+9u5MkDdHIEfgy4MqI2AvcC1waEXc3JZUkaUx1F3hmfjkzF2TmQuA64N8yc1XTkkmSRuV54JJUqK5m3ElmbgQ2NuO+JEnj4xG4JBXKApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFcoCl6RCWeCSVCgLXJIKZYFLUqEscEkqlAUuSYWywCWpUBa4JBXKApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpELVXeARcVpEfDcidkbE9ohY08xgkqTRdTWw7TvAH2bmloiYBWyOiMcyc0eTskmSRlH3EXhm7s/MLdX0G8BOYH6zgkmSRteUMfCIWAicB2wa5rbVEdEXEX0DAwPN2J0kiSYUeEScANwPfCEzXx96e2auy8zezOzt6elpdHeSpEpDBR4RU6mV9z2Z+UBzIkmSxqORs1AC+CawMzP/vHmRJEnj0cgR+DLgN4BLI2Jr9bWySbkkSWOo+zTCzPwvIJqYRZI0AV6JKUmFssAlqVAWuCQVygKXpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFcoCl6RCWeCSVCgLXJIKZYFLUqEscEkqlAUuSYWywCWpUBa4JBXKApekQlngklQoC1ySCmWBS1KhLHBJKpQFLkmFssAlqVAWuCQVygKXpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5JhbLAJalQFrgkFaqhAo+IFRHxXEQ8HxFrmxVKkjS2ugs8IqYAfw1cBpwFfDYizmpWMEnS6Bo5Ar8IeD4zX8jMt4F7gauaE0uSNJauBradD+wbNN8P/MLQlSJiNbC6mn0rIrY1sM9WOwn48WSHGIX56tfJ2cB8jfqw5/u54RY2UuAxzLL8wILMdcA6gIjoy8zeBvbZUuZrTCfn6+RsYL5GfVTzNTKE0g+cNmh+AfBKY3EkSePVSIH/N/CxiFgUEccB1wHfaU4sSdJY6h5Cycx3IuL3gH8FpgDrM3P7GJutq3d/bWK+xnRyvk7OBuZr1EcyX2R+YNhaklQAr8SUpEJZ4JJUqLYUeCdcch8Rp0XEdyNiZ0Rsj4g11fK5EfFYROyuvs8ZtM2Xq8zPRcSvtCnnlIh4JiIe7rR8ETE7Iu6LiF3Vz/HiTskXEV+s/l23RcSGiJg22dkiYn1EvDr42od6MkXEBRHxg+q22yJiuFN4m5Hta9W/7fcj4sGImD0Z2UbKN+i2P4qIjIiTOi1fRNxQZdgeEbe0PF9mtvSL2huce4DTgeOAZ4GzWr3fYXLMA86vpmcB/0PtTwDcAqytlq8FvlpNn1VlPR5YVD2GKW3I+QfAPwAPV/Mdkw/4W+C3q+njgNmdkI/aRWUvAtOr+W8Dn5vsbMAngfOBbYOWTTgT8D3gYmrXXvwzcFmLsv0y0FVNf3Wyso2Ur1p+GrUTJ34InNRJ+YBfAh4Hjq/mT251vnYcgXfEJfeZuT8zt1TTbwA7qT3xr6JWTFTfr66mrwLuzcy3MvNF4Hlqj6VlImIBcDlw16DFHZEvIk6k9kv7TYDMfDszD3ZKPmpnVE2PiC5gBrVrEiY1W2b+B/B/QxZPKFNEzANOzMynsvaM/7tB2zQ1W2Y+mpnvVLNPU7u2o+3ZRspX+QvgSxx70WCn5Ptd4ObMfKta59VW52tHgQ93yf38Nux3RBGxEDgP2ASckpn7oVbywMnVapOR+1Zqv5w/HbSsU/KdDgwA36qGeO6KiJmdkC8zXwa+DrwE7Adey8xHOyHbMCaaaX41PXR5q/0WtSPCjskWEVcCL2fms0Nu6oh8wMeBX4yITRHx7xFxYavztaPAx3XJfbtExAnA/cAXMvP10VYdZlnLckfEFcCrmbl5vJsMs6yVP9cuai8Zv5GZ5wE/oTYEMJK25avGka+i9vL0VGBmRKzqhGwTMFKmtmeNiBuBd4B7ji4aIUM7/41nADcCfzLczSPkmIznyBxgKfDHwLerMe2W5WtHgXfMJfcRMZVaed+TmQ9Ui39UvZSh+n70ZU+7cy8DroyIvdSGmS6NiLs7KF8/0J+Zm6r5+6gVeifk+zTwYmYOZOYR4AHgEx2SbaiJZurn/aGMwctbIiKuB64Afr16Wd8p2X6e2n/Qz1bPkQXAloj42Q7JR7W/B7Lme9ReSZ/U0nzNGNAfY7C/C3iB2g//6JuYZ7d6v8PkCGpjTLcOWf41jn1T6ZZq+myOfePhBdrwJma17+W8/yZmx+QD/hNYXE3/aZVt0vNR+yuY26mNfQe1seUbOiTbQo59o2vCmaj92YqlvP9G18oWZVsB7AB6hqzX9mzD5Rty217efxOzI/IBvwP8WTX9cWrDJtHKfE3/hR3hga6kdtbHHuDGduxzmAyXUHt58n1ga/W1EugGngB2V9/nDtrmxirzczTp3etxZl3O+wXeMfmAJUBf9TP8R2ovFzsiH/AVYBewDfj76skyqdmADdTG5I9QO9r6fD2ZgN7qce0B/orqCuoWZHu+Kp2jz487JiPbSPmG3L6XqsA7JR+1A9S7q/1tAS5tdT4vpZekQnklpiQVygKXpEJZ4JJUKAtckgplgUtSoSxwSSqUBS5Jhfp/y7IlHkW4+9kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='34' class='' max='1680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      2.02% [34/1680 00:09<07:28 7.1965]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b5a7e19d6581>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# learn.fit_one_cycle(1, 1e-2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelStepException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1, 1e-3) # learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|experiment |epochs| train_loss| valid_loss |accuracy  | perplexity |time | notes                 |\n",
    "|-----------|------|-----------|------------|----------|------------|-----|:---------------------:|\n",
    "|     a     |  1   |19.061800  | 45.006886  | 0.090237 |     -      |09:10|          -            |\n",
    "|     b     |  1   |5.943309   | 7.154285   | 0.090238 |1279.577148\t|09:38| only predicts `xxmaj` |\n",
    "\n",
    "Objetive (in 10 epochs) [video](https://youtu.be/vnOpEwmtFJ8?t=7549): train_loss=4.03 valid_loss=4.06 valid_accuracy=0.2867"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model(batch_x.cuda()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_p = learn.model(batch_x.cuda()).cpu()\n",
    "batch_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(new_batch_p, batch_y.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 7, 7,  ..., 7, 7, 7],\n",
       "        [7, 7, 7,  ..., 7, 7, 7],\n",
       "        [7, 7, 7,  ..., 7, 7, 7],\n",
       "        ...,\n",
       "        [7, 7, 7,  ..., 7, 7, 7],\n",
       "        [7, 7, 7,  ..., 7, 7, 7],\n",
       "        [7, 7, 7,  ..., 7, 7, 7]], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = new_batch_p.argmax(dim=-1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7], device='cuda:0'), tensor([4480], device='cuda:0'))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(learn.model.state_dict(), './language_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Model: AWD-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide the zeros&ones mask to **mantain the std** at applying the droput mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_mask(x, size, drop_prob):\n",
    "    return x.new(*size).bernoulli_(drop_prob).div_(drop_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., 10., 10.,  0.,  0.,  0., 10.,  0.],\n",
       "        [10.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., 10.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0., 10.,  0.,  0., 10.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0., 10.,  0.,  0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(10,10)\n",
    "mask = dropout_mask(t, (10,10), 0.1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `EmbeddingDropout` (aka `TokenDropout`)\n",
    "- EmbeddingDropout applies dropout to the whole embedding matrix, to make the some rows equals zeros.\n",
    "- THIS dropout is NOT APPLIEID ON THE OUTPUT of the embeding layer. TH dROP OUT IS APPLIED TO THE EMBEDDING WEITHS themselfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 2, 1],\n",
       "        [0, 3, 2, 1, 2]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.LongTensor([[0, 1, 2, 2, 1],\n",
    "                          [0, 3, 2, 1, 2]])\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6585, -0.0951, -1.0614,  0.8276, -0.3901,  1.5006, -0.8054],\n",
       "         [ 0.0229, -0.1936,  0.4089,  0.5277, -0.1738, -0.3447,  0.4222],\n",
       "         [-0.9440,  0.7588,  0.0509, -1.0544, -0.6787, -2.0373, -0.0296],\n",
       "         [-0.9440,  0.7588,  0.0509, -1.0544, -0.6787, -2.0373, -0.0296],\n",
       "         [ 0.0229, -0.1936,  0.4089,  0.5277, -0.1738, -0.3447,  0.4222]],\n",
       "\n",
       "        [[-0.6585, -0.0951, -1.0614,  0.8276, -0.3901,  1.5006, -0.8054],\n",
       "         [ 0.0906,  0.6282,  1.3173,  0.0417, -0.1491, -0.4256,  0.0710],\n",
       "         [-0.9440,  0.7588,  0.0509, -1.0544, -0.6787, -2.0373, -0.0296],\n",
       "         [ 0.0229, -0.1936,  0.4089,  0.5277, -0.1738, -0.3447,  0.4222],\n",
       "         [-0.9440,  0.7588,  0.0509, -1.0544, -0.6787, -2.0373, -0.0296]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = nn.Embedding(num_embeddings=100, embedding_dim=7, padding_idx=99) # For padding_idx will return a vector of zeros\n",
    "out_emb = emb(input)\n",
    "out_emb # [BS, SEQ_LEN, EMB_DIM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = torch.distributions.bernoulli.Bernoulli(0.3)\n",
    "dropout.sample(sample_shape=(out_emb.shape[1], ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out_emb.shape[1], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'Bernoulli'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-3af275b595d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'Bernoulli'"
     ]
    }
   ],
   "source": [
    "torch.Bernoulli(0.3).sample((out.shape[1], ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.LongTensor([[0, 1, 2, 2, 1],\n",
    "                          [0, 3, 2, 1, 2]])\n",
    "\n",
    "out = emb(input)\n",
    "rw = Bernoulli(0.3).sample((out.shape[1], ))\n",
    "\n",
    "out[:, rw==1].mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21, 32, 49, 61, 42])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_input = torch.randint(low=0, high=100, size=(5,))\n",
    "tst_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3420, -1.4190,  0.7275, -0.6516, -2.5164,  1.8570, -1.4382,  0.4643],\n",
       "        [-0.8923, -0.3391, -0.3041, -1.3148,  1.4897,  0.1525,  1.4502,  0.0357],\n",
       "        [-0.0545, -2.0934, -1.7578, -0.4612,  1.1825, -0.5089, -0.1025, -0.1985],\n",
       "        [ 0.9805, -0.6491, -0.5569, -0.6984,  0.2961, -1.0677,  1.8033, -0.0987],\n",
       "        [ 0.4785, -1.3237, -1.3687, -0.5233, -1.0823,  0.4919, -1.1676, -0.7927]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc(tst_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = nn.Dropout2d(p=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4275, -0.0000,  0.0000, -0.8145, -3.1455,  2.3213, -1.7978,  0.5804],\n",
       "        [-0.0000, -0.4239, -0.3801, -0.0000,  1.8621,  0.1906,  0.0000,  0.0446],\n",
       "        [-0.0682, -0.0000, -0.0000, -0.5765,  1.4781, -0.0000, -0.1282, -0.2481],\n",
       "        [ 1.2256, -0.0000, -0.6961, -0.8730,  0.0000, -0.0000,  0.0000, -0.1234],\n",
       "        [ 0.5982, -1.6546, -0.0000, -0.6541, -1.3528,  0.6148, -1.4595, -0.9909]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d(enc(tst_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDropout(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb, embed_p):\n",
    "        super().__init__()\n",
    "        self.emb,self.embed_p = emb,embed_p\n",
    "        self.pad_idx = self.emb.padding_idx\n",
    "        if self.pad_idx is None: self.pad_idx = -1\n",
    " \n",
    "    def forward(self, words, scale=None):\n",
    "        if self.training and self.embed_p != 0:\n",
    "            size = (self.emb.weight.size(0),1)\n",
    "            mask = dropout_mask(self.emb.weight.data, size, self.embed_p)\n",
    "            masked_embed = self.emb.weight * mask\n",
    "        else:\n",
    "            masked_embed = self.emb.weight\n",
    "        if scale:\n",
    "            masked_embed.mul_(scale)\n",
    "        return F.embedding(words, masked_embed, self.pad_idx, self.emb.max_norm,\n",
    "                           self.emb.norm_type, self.emb.scale_grad_by_freq, self.emb.sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.functional' has no attribute 'embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-86d8e50d511b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0menc_dp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbeddingDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtst_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtst_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_dp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-1bc7860daaf7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, words, scale)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mmasked_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         return F.embedding(words, masked_embed, self.pad_idx, self.emb.max_norm,\n\u001b[0m\u001b[1;32m     19\u001b[0m                            self.emb.norm_type, self.emb.scale_grad_by_freq, self.emb.sparse)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.functional' has no attribute 'embedding'"
     ]
    }
   ],
   "source": [
    "enc = nn.Embedding(100, 7, padding_idx=1)\n",
    "enc_dp = EmbeddingDropout(enc, 0.5)\n",
    "tst_input = torch.randint(0,100,(8,))\n",
    "tst_input, enc_dp(tst_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RNNDropout` (aka `SequenceDropout`)\n",
    "Dropout on the entire sequence dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RNNDropout(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p=p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training or self.p == 0.: return x\n",
    "        m = dropout_mask(x.data, (x.size(0), 1, x.size(2)), self.p)\n",
    "        return x * m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `WeightDropout`(aka `DropConnect`)\n",
    "This is dropout not on the activations but **on the weights themselfs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "WEIGHT_HH = 'weight_hh_l0'\n",
    "\n",
    "class WeightDropout(nn.Module):\n",
    "    def __init__(self, module, weight_p=[0.], layer_names=[WEIGHT_HH]):\n",
    "        super().__init__()\n",
    "        self.module,self.weight_p,self.layer_names = module,weight_p,layer_names\n",
    "        for layer in self.layer_names:\n",
    "            #Makes a copy of the weights of the selected layers.\n",
    "            w = getattr(self.module, layer)\n",
    "            self.register_parameter(f'{layer}_raw', nn.Parameter(w.data))\n",
    "            self.module._parameters[layer] = F.dropout(w, p=self.weight_p, training=False)\n",
    "\n",
    "    def _setweights(self):\n",
    "        for layer in self.layer_names:\n",
    "            raw_w = getattr(self, f'{layer}_raw')\n",
    "            self.module._parameters[layer] = F.dropout(raw_w, p=self.weight_p, training=self.training)\n",
    "\n",
    "    def forward(self, *args):\n",
    "        self._setweights() # HERE WE APPLY DROPCONNECT\n",
    "        with warnings.catch_warnings():\n",
    "            #To avoid the warning that comes because the weights aren't flattened.\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            return self.module.forward(*args)\n",
    "        \n",
    "DropConnect = WeightDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main model: `AWD_LSTM`\n",
    "- The main model is a regular LSTM with several layers, but using all those kinds of dropouts.\n",
    "- This is AWD-LSTM inspired by https://arxiv.org/abs/1708.02182."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    input_size: The number of expected features in the input `x`\n",
    "    hidden_size: The number of features in the hidden state `h`\n",
    "    num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n",
    "        would mean stacking two LSTMs together to form a `stacked LSTM`,\n",
    "        with the second LSTM taking in outputs of the first LSTM and\n",
    "        computing the final results. Default: 1\n",
    "    bias\n",
    "    \n",
    "    \n",
    "[nn.LSTM(input_size  = emb_sz if l == 0 else n_hid,\n",
    "         hidden_size = (n_hid if l != n_layers - 1 else emb_sz),\n",
    "         num_layers  = 1,\n",
    "         batch_first = True) for l in range(n_layers) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWDLSTM_body(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_sz, emb_sz, n_hid, n_layers, pad_token,\n",
    "                 hidden_p=0.2,\n",
    "                 input_p=0.6,\n",
    "                 embed_dropout_prob  = 0.1, # aka TokenDropout\n",
    "                 weight_dropout_prob = 0.5):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bs,self.emb_sz,self.n_hid,self.n_layers = 1,emb_sz,n_hid,n_layers\n",
    "        \n",
    "        # Embeding\n",
    "        self.emb    = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_token)\n",
    "        emb_init_range = 0.1\n",
    "        self.emb.weight.data.uniform_(-emb_init_range, emb_init_range)\n",
    "        \n",
    "        # LSTMs\n",
    "        self.rnns = [nn.LSTM(input_size  = emb_sz if l == 0 else n_hid,\n",
    "                             hidden_size = (n_hid if l != n_layers - 1 else emb_sz),\n",
    "                             num_layers  = 1,\n",
    "                             batch_first = True) for l in range(n_layers) ]\n",
    "        \n",
    "        # Dropouts\n",
    "        self.emb_dp = EmbeddingDropout(self.emb, embed_dropout_prob)\n",
    "        self.input_dp = RNNDropout(input_p)\n",
    "        self.rnns = nn.ModuleList([WeightDropout(rnn, weight_dropout_prob) for rnn in self.rnns])\n",
    "        self.hidden_dps = nn.ModuleList([RNNDropout(hidden_p) for l in range(n_layers)])\n",
    "\n",
    "    def forward(self, input):\n",
    "        bs,sl = input.size()\n",
    "        if bs!=self.bs:\n",
    "            self.bs=bs\n",
    "            self.reset()\n",
    "        raw_output = self.input_dp(self.emb_dp(input))\n",
    "        new_hidden,raw_outputs,outputs = [],[],[]\n",
    "        \n",
    "        for l, (rnn,hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):\n",
    "            raw_output, new_h = rnn(raw_output, self.hidden[l])\n",
    "            new_hidden.append(new_h)\n",
    "            raw_outputs.append(raw_output)\n",
    "            if l != self.n_layers - 1: raw_output = hid_dp(raw_output)\n",
    "            outputs.append(raw_output) \n",
    "        self.hidden = to_detach(new_hidden)\n",
    "        return raw_outputs, outputs\n",
    "    \n",
    "    def to_detach(h):\n",
    "        \"Detaches `h` from its history.\"\n",
    "        return h.detach() if type(h) == torch.Tensor else tuple(to_detach(v) for v in h)\n",
    "\n",
    "    def _one_hidden(self, l):\n",
    "        \"Return one hidden state.\"\n",
    "        nh = self.n_hid if l != self.n_layers - 1 else self.emb_sz\n",
    "        return next(self.parameters()).new(1, self.bs, nh).zero_()\n",
    "\n",
    "    def reset(self):\n",
    "        \"Reset the hidden states.\"\n",
    "        self.hidden = [(self._one_hidden(l), self._one_hidden(l)) for l in range(self.n_layers)]\n",
    "\n",
    "\n",
    "class AWDLSTM_linearHead(nn.Module):\n",
    "    def __init__(self, n_out, n_hid, output_p, tie_encoder=None, bias=True):\n",
    "        super().__init__()\n",
    "        self.output_dp = RNNDropout(output_p)\n",
    "        self.decoder = nn.Linear(n_hid, n_out, bias=bias)\n",
    "        if bias: self.decoder.bias.data.zero_()\n",
    "        if tie_encoder: self.decoder.weight = tie_encoder.weight\n",
    "        else: init.kaiming_uniform_(self.decoder.weight)\n",
    "\n",
    "    def forward(self, input):\n",
    "        raw_outputs, outputs = input\n",
    "        output = self.output_dp(outputs[-1]).contiguous()\n",
    "        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n",
    "        return decoded, raw_outputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
