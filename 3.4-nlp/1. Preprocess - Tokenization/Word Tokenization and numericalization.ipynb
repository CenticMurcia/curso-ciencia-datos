{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Preprocess .txt dataset\n",
    "# <center> `read_file` -> `tokenize` -> `numericalize`\n",
    "> Notebook based on:\n",
    "> 1. **https://github.com/fastai/course-v3/blob/master/nbs/dl2/12_text.ipynb**\n",
    "> 2. https://github.com/fastai/course-v3/blob/master/nbs/dl2/12a_awd_lstm.ipynb\n",
    "> 3. https://github.com/fastai/course-v3/blob/master/nbs/dl2/12b_lm_pretrain.ipynb\n",
    "> 4. https://github.com/fastai/course-v3/blob/master/nbs/dl2/12c_ulmfit.ipynb\n",
    "> \n",
    "> Video:\n",
    "> - https://youtu.be/vnOpEwmtFJ8?t=4687 from 1:18:00 to 2:08:00 (50 mins)\n",
    "> \n",
    "> [Usuful blog post about Pytorch Dataset, Dataloader, Samplers and collate](https://www.scottcondron.com/jupyter/visualisation/audio/2020/12/02/dataloaders-samplers-collate.html)\n",
    "\n",
    "# Steps\n",
    "1. Load the text data\n",
    "2. Tokenizing (Spacy + Custom tokens)\n",
    "3. Create vocab\n",
    "4. Numeralization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fastai.text.all import *\n",
    "\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "import torch\n",
    "\n",
    "# For tokenizing\n",
    "import re\n",
    "import html\n",
    "import spacy\n",
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from spacy.symbols import ORTH\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACY_TOKENIZER = spacy.blank(\"en\").tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  train  unsup\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"../../Datasets/NLP/IMBd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg  pos\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"../../Datasets/NLP/IMBd/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../../Datasets/NLP/IMBd')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = pathlib.Path(\"../../Datasets/NLP/IMBd\")\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = list( (data_path/\"train\").glob('**/*.txt') )\n",
    "valid_filenames = list( (data_path/\"test\").glob('**/*.txt') )\n",
    "unsup_filenames = list( (data_path/\"unsup\").glob('**/*.txt') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 25000 reviews\n",
      "Test:  25000 reviews\n",
      "Unsup: 50000 reviews\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", len(train_filenames), \"reviews\")\n",
    "print(\"Test: \", len(valid_filenames), \"reviews\")\n",
    "print(\"Unsup:\", len(unsup_filenames), \"reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = train_filenames + valid_filenames + unsup_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(text_file): \n",
    "    with open(text_file, 'r', encoding='utf8') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The choice to make this SNL skit into a movie was far better thought out than other recent ones. The humor involved in the character is not annoyance humor, and is also character driven enough to be stretched out for an hour or two.<br /><br />Oddly enough the sexual content seemed like it could be avoided, but that may have been because the constraints of live television schooled me to not expect it. I suppose I was thinking more \"Leisure Suit Larry\" risqu√© than the producers were...<br /><br />Definitely not a PG-13 movie, which will probably hurt it from ever reaching the heights of its more successful predecessors, but still better premise and writing than its more dismal ones.<br /><br />I liked it, but I doubt it will be a smash hit... (which is sad, as Tim Meadows tends not to do characters that annoy me with quite the frequency other SNL alumni tend to)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_file(filenames[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special tokens\n",
    "0. `xxunk`: Indicates the word is **unknown**. [`jkajkadsa`] -> [`xxunk`]\n",
    "1. `xxpad`: Indicates **padding** (no more content)\n",
    "2. `xxbos`: Indicates the **beginning of stream** (here, a movie review).\n",
    "3. `xxeos`: Indicates the **end of stream** (here, a movie review).\n",
    "4. `xxfld`: Indicates separate **fields** (parts like title, summary etc).\n",
    "5. `xxrep`: Indicates **repetition**. [`hello!!!!`] -> [`hello`, `xxrep`, `4`, `!`]\n",
    "6. `xxwrep`: Indicates **word repetition**. [`hello`, `hello`, `hello`] -> [`xxwrep`,`3`, `hello`]\n",
    "7. `xxup`: Indicates the next word is all in capital (since we lowercased everything). [`GOD`] -> [`xxup`, `god`]\n",
    "8. `xxmaj`: Indicates the next word begins with a capital (since we lowercased everything). [`This`] -> [`xxmaj`, `this`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK     = \"xxunk\"  # 0\n",
    "PAD     = \"xxpad\"  # 1\n",
    "BOS     = \"xxbos\"  # 3\n",
    "EOS     = \"xxeos\"  # 4\n",
    "TK_REP  = \"xxrep\"  # 5\n",
    "TK_WREP = \"xxwrep\" # 6\n",
    "TK_UP   = \"xxup\"   # 7\n",
    "TK_MAJ  = \"xxmaj\"  # 8\n",
    "\n",
    "default_spec_tok = [UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-tokenization rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_br(t):\n",
    "    \"Replaces the <br /> by \\n\"\n",
    "    re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "    return re_br.sub(\"\\n\", t)\n",
    "\n",
    "def spec_add_spaces(t):\n",
    "    \"Add spaces around / and #\"\n",
    "    return re.sub(r'([/#])', r' \\1 ', t)\n",
    "\n",
    "def rm_useless_spaces(t):\n",
    "    \"Remove multiple spaces\"\n",
    "    return re.sub(' {2,}', ' ', t)\n",
    "\n",
    "def replace_rep(t):\n",
    "    \"Replace repetitions at the character level: cccc -> TK_REP 4 c\"\n",
    "    def _replace_rep(m) -> str:\n",
    "        c,cc = m.groups()\n",
    "        return f' {TK_REP} {len(cc)+1} {c} '\n",
    "    re_rep = re.compile(r'(\\S)(\\1{3,})')\n",
    "    return re_rep.sub(_replace_rep, t)\n",
    "    \n",
    "def replace_wrep(t):\n",
    "    \"Replace word repetitions: word word word -> TK_WREP 3 word\"\n",
    "    def _replace_wrep(m) -> str:\n",
    "        c,cc = m.groups()\n",
    "        return f' {TK_WREP} {len(cc.split())+1} {c} '\n",
    "    re_wrep = re.compile(r'(\\b\\w+\\W+)(\\1{3,})')\n",
    "    return re_wrep.sub(_replace_wrep, t)\n",
    "\n",
    "def fixup_text(x):\n",
    "    \"Various messy things we've seen in documents\"\n",
    "    re1 = re.compile(r'  +')\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>',UNK).replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "    \n",
    "default_pre_rules = [fixup_text, replace_rep, replace_wrep, spec_add_spaces, rm_useless_spaces, sub_br]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' xxrep 4 c '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_rep('cccc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' xxwrep 5 word  '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_wrep('word word word word word ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Tokenization rules\n",
    "These rules are applies after the tokenization on the list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all_caps(x):\n",
    "    \"Replace tokens in ALL CAPS by their lower version and add `TK_UP` before.\"\n",
    "    res = []\n",
    "    for t in x:\n",
    "        if t.isupper() and len(t) > 1: res.append(TK_UP); res.append(t.lower())\n",
    "        else: res.append(t)\n",
    "    return res\n",
    "\n",
    "def deal_caps(x):\n",
    "    \"Replace all Capitalized tokens in by their lower version and add `TK_MAJ` before.\"\n",
    "    res = []\n",
    "    for t in x:\n",
    "        if t == '': continue\n",
    "        if t[0].isupper() and len(t) > 1 and t[1:].islower(): res.append(TK_MAJ)\n",
    "        res.append(t.lower())\n",
    "    return res\n",
    "\n",
    "def add_eos_bos(x):\n",
    "    return [BOS] + x + [EOS]\n",
    "\n",
    "default_post_rules = [deal_caps, replace_all_caps, add_eos_bos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'xxup', 'am', 'xxup', 'shouting']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_all_caps(['I', 'AM', 'SHOUTING'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxmaj', 'my', 'name', 'is', 'xxmaj', 'javi']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deal_caps(['My', 'name', 'is', 'Javi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxbos', 'My', 'name', 'is', 'Javi', 'xxeos']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_eos_bos(['My', 'name', 'is', 'Javi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer = `Pre rules` -> `Spacy English word tokenizer` -> `Post rules`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \n",
    "    ######### Apply pre rules\n",
    "    for pre_rule in default_pre_rules: text = pre_rule(text)\n",
    "        \n",
    "    ######### SPACY English Tokenizer\n",
    "    tokens = [str(token) for token in SPACY_TOKENIZER(text)]\n",
    "    \n",
    "    ######### Apply post rules\n",
    "    for post_rule in default_post_rules: tokens = post_rule(tokens)\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj hello , my name is xxmaj javi xxrep 4 ! xxeos'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(tokenize(\"Hello, my name is Javi!!!!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize texts (in Parallel)\n",
    "Since tokenizing and applying those rules takes a bit of time, we'll parallelize it using `ProcessPoolExecutor` to go faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_map(func, array):\n",
    "    \n",
    "    cpu_cores = multiprocessing.cpu_count()\n",
    "    array_len = len(array)\n",
    "    chunksize = array_len // 100\n",
    "    \n",
    "    if cpu_cores<2:\n",
    "        return list(tqdm(map(func, arr), total=array_len))\n",
    "    else:\n",
    "        with ProcessPoolExecutor(max_workers=cpu_cores) as ex:\n",
    "            return list(tqdm(ex.map(func, array, chunksize=chunksize), total=array_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9e29a225044a05949999c9b7a04a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def readfile_and_tokenize(filename):\n",
    "    return tokenize(read_file(filename))\n",
    "\n",
    "texts_toks = parallel_map(func=readfile_and_tokenize, array=filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Voacab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172700 different tokens exists\n",
      "89384 tokens appears at least 2 times\n",
      "70718 tokens appears at least 3 times\n",
      "54932 tokens appears at least 5 times\n"
     ]
    }
   ],
   "source": [
    "def create_vocab(texts_toks, max_vocab=65536, min_freq=2): # 60000\n",
    "    \n",
    "    # Count number of occurrences for each token\n",
    "    token_counts = Counter(p for o in texts_toks for p in o)\n",
    "    \n",
    "    print( len(token_counts),                                    \"different tokens exists\")\n",
    "    print( len([t for t in token_counts if token_counts[t]>=2]), \"tokens appears at least 2 times\")\n",
    "    print( len([t for t in token_counts if token_counts[t]>=3]), \"tokens appears at least 3 times\")\n",
    "    print( len([t for t in token_counts if token_counts[t]>=5]), \"tokens appears at least 5 times\")\n",
    "    \n",
    "    # Create vocab limiting some words\n",
    "    vocab = [o for o,c in token_counts.most_common(max_vocab) if c >= min_freq]\n",
    "    \n",
    "    # Put special tokens (xx) at the begining of the list\n",
    "    for o in default_spec_tok[::-1]:\n",
    "        if o in vocab:\n",
    "            vocab.remove(o)\n",
    "        vocab.insert(0, o)\n",
    "        \n",
    "    return vocab\n",
    "\n",
    "vocab = create_vocab(texts_toks, max_vocab=65536, min_freq=2)\n",
    "del texts_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab with 65539 different tokens in IMDb\n",
      "\n",
      "First tokens in the vocab:\n",
      "['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxrep', 'xxwrep', 'xxup', 'xxmaj', 'the', '.', ',', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this', 'that', '\"', \"'s\", '-', '\\n\\n', 'was', 'as', 'with', 'for', 'movie', 'but', 'film', 'you', ')', 'on', \"n't\", '(', 'not', 'are', 'he', 'his', 'have', 'be', 'one', 'all', 'at', 'they', 'by', 'an', 'who']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab with\", len(vocab), \"different tokens in IMDb\")\n",
    "print(\"\\nFirst tokens in the vocab:\")\n",
    "print(vocab[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab saved on ../../Datasets/NLP/IMBd/vocab.pkl\n"
     ]
    }
   ],
   "source": [
    "vocab_file = open(data_path/'vocab.pkl','wb')\n",
    "pickle.dump(vocab, vocab_file)\n",
    "print(\"Vocab saved on\", str(data_path/'vocab.pkl'))\n",
    "\n",
    "######################## Test for reading vocab file \n",
    "vocab_file = open(data_path/'vocab.pkl','rb')\n",
    "assert pickle.load(vocab_file) == vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Numericalizing\n",
    "Once we have tokenized our texts, we replace each token by an individual number, this is called numericalizing.\n",
    "    \n",
    "If the token string does not extist we assign 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int -> is for returning 0 when the token string does not exists\n",
    "otoi = defaultdict(int, {o:i for i,o in enumerate(vocab)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'xxunk': 0,\n",
       "             'xxpad': 1,\n",
       "             'xxbos': 2,\n",
       "             'xxeos': 3,\n",
       "             'xxrep': 4,\n",
       "             'xxwrep': 5,\n",
       "             'xxup': 6,\n",
       "             'xxmaj': 7,\n",
       "             'the': 8,\n",
       "             '.': 9,\n",
       "             ',': 10,\n",
       "             'and': 11,\n",
       "             'a': 12,\n",
       "             'of': 13,\n",
       "             'to': 14,\n",
       "             'is': 15,\n",
       "             'it': 16,\n",
       "             'in': 17,\n",
       "             'i': 18,\n",
       "             'this': 19,\n",
       "             'that': 20,\n",
       "             '\"': 21,\n",
       "             \"'s\": 22,\n",
       "             '-': 23,\n",
       "             '\\n\\n': 24,\n",
       "             'was': 25,\n",
       "             'as': 26,\n",
       "             'with': 27,\n",
       "             'for': 28,\n",
       "             'movie': 29,\n",
       "             'but': 30,\n",
       "             'film': 31,\n",
       "             'you': 32,\n",
       "             ')': 33,\n",
       "             'on': 34,\n",
       "             \"n't\": 35,\n",
       "             '(': 36,\n",
       "             'not': 37,\n",
       "             'are': 38,\n",
       "             'he': 39,\n",
       "             'his': 40,\n",
       "             'have': 41,\n",
       "             'be': 42,\n",
       "             'one': 43,\n",
       "             'all': 44,\n",
       "             'at': 45,\n",
       "             'they': 46,\n",
       "             'by': 47,\n",
       "             'an': 48,\n",
       "             'who': 49,\n",
       "             '!': 50,\n",
       "             'from': 51,\n",
       "             'so': 52,\n",
       "             'like': 53,\n",
       "             'there': 54,\n",
       "             'or': 55,\n",
       "             'just': 56,\n",
       "             'her': 57,\n",
       "             'do': 58,\n",
       "             'about': 59,\n",
       "             'out': 60,\n",
       "             'has': 61,\n",
       "             \"'\": 62,\n",
       "             'if': 63,\n",
       "             'what': 64,\n",
       "             'some': 65,\n",
       "             '?': 66,\n",
       "             'good': 67,\n",
       "             'when': 68,\n",
       "             'more': 69,\n",
       "             'very': 70,\n",
       "             'she': 71,\n",
       "             'up': 72,\n",
       "             'would': 73,\n",
       "             'no': 74,\n",
       "             'time': 75,\n",
       "             'even': 76,\n",
       "             'my': 77,\n",
       "             'can': 78,\n",
       "             'their': 79,\n",
       "             'which': 80,\n",
       "             'only': 81,\n",
       "             'story': 82,\n",
       "             'really': 83,\n",
       "             'see': 84,\n",
       "             'had': 85,\n",
       "             'were': 86,\n",
       "             'did': 87,\n",
       "             'well': 88,\n",
       "             'me': 89,\n",
       "             'we': 90,\n",
       "             'does': 91,\n",
       "             '...': 92,\n",
       "             'than': 93,\n",
       "             'much': 94,\n",
       "             ':': 95,\n",
       "             'could': 96,\n",
       "             'bad': 97,\n",
       "             'get': 98,\n",
       "             'been': 99,\n",
       "             'people': 100,\n",
       "             'great': 101,\n",
       "             'other': 102,\n",
       "             'also': 103,\n",
       "             'into': 104,\n",
       "             'will': 105,\n",
       "             'first': 106,\n",
       "             'because': 107,\n",
       "             'him': 108,\n",
       "             'how': 109,\n",
       "             'most': 110,\n",
       "             'them': 111,\n",
       "             'its': 112,\n",
       "             'made': 113,\n",
       "             'make': 114,\n",
       "             'then': 115,\n",
       "             'way': 116,\n",
       "             'too': 117,\n",
       "             'movies': 118,\n",
       "             'after': 119,\n",
       "             'any': 120,\n",
       "             'characters': 121,\n",
       "             'think': 122,\n",
       "             'character': 123,\n",
       "             '/': 124,\n",
       "             'films': 125,\n",
       "             'watch': 126,\n",
       "             'two': 127,\n",
       "             'many': 128,\n",
       "             'being': 129,\n",
       "             'plot': 130,\n",
       "             'seen': 131,\n",
       "             'never': 132,\n",
       "             'love': 133,\n",
       "             ';': 134,\n",
       "             'where': 135,\n",
       "             'life': 136,\n",
       "             'acting': 137,\n",
       "             'little': 138,\n",
       "             'best': 139,\n",
       "             'know': 140,\n",
       "             'off': 141,\n",
       "             'show': 142,\n",
       "             'over': 143,\n",
       "             'ever': 144,\n",
       "             'man': 145,\n",
       "             'better': 146,\n",
       "             'your': 147,\n",
       "             'end': 148,\n",
       "             'here': 149,\n",
       "             'scene': 150,\n",
       "             'these': 151,\n",
       "             'still': 152,\n",
       "             'while': 153,\n",
       "             'why': 154,\n",
       "             'should': 155,\n",
       "             'scenes': 156,\n",
       "             'say': 157,\n",
       "             'something': 158,\n",
       "             'go': 159,\n",
       "             \"'ve\": 160,\n",
       "             'such': 161,\n",
       "             'back': 162,\n",
       "             'through': 163,\n",
       "             'real': 164,\n",
       "             'those': 165,\n",
       "             'now': 166,\n",
       "             \"'m\": 167,\n",
       "             'watching': 168,\n",
       "             'thing': 169,\n",
       "             'director': 170,\n",
       "             'actors': 171,\n",
       "             'funny': 172,\n",
       "             'though': 173,\n",
       "             'years': 174,\n",
       "             'another': 175,\n",
       "             'old': 176,\n",
       "             'actually': 177,\n",
       "             'nothing': 178,\n",
       "             'work': 179,\n",
       "             'before': 180,\n",
       "             'makes': 181,\n",
       "             'going': 182,\n",
       "             'new': 183,\n",
       "             '10': 184,\n",
       "             'look': 185,\n",
       "             'find': 186,\n",
       "             'same': 187,\n",
       "             'lot': 188,\n",
       "             '--': 189,\n",
       "             'every': 190,\n",
       "             'few': 191,\n",
       "             'part': 192,\n",
       "             'again': 193,\n",
       "             '*': 194,\n",
       "             'world': 195,\n",
       "             'cast': 196,\n",
       "             'ca': 197,\n",
       "             'things': 198,\n",
       "             'us': 199,\n",
       "             \"'re\": 200,\n",
       "             'horror': 201,\n",
       "             '&': 202,\n",
       "             'down': 203,\n",
       "             'want': 204,\n",
       "             'quite': 205,\n",
       "             'pretty': 206,\n",
       "             'got': 207,\n",
       "             'around': 208,\n",
       "             'seems': 209,\n",
       "             'young': 210,\n",
       "             'action': 211,\n",
       "             'fact': 212,\n",
       "             'take': 213,\n",
       "             'enough': 214,\n",
       "             'however': 215,\n",
       "             'long': 216,\n",
       "             'thought': 217,\n",
       "             'both': 218,\n",
       "             'big': 219,\n",
       "             'give': 220,\n",
       "             'own': 221,\n",
       "             'comedy': 222,\n",
       "             'between': 223,\n",
       "             '4': 224,\n",
       "             'must': 225,\n",
       "             'series': 226,\n",
       "             'may': 227,\n",
       "             'right': 228,\n",
       "             'without': 229,\n",
       "             'guy': 230,\n",
       "             'original': 231,\n",
       "             'role': 232,\n",
       "             'times': 233,\n",
       "             'come': 234,\n",
       "             'saw': 235,\n",
       "             'always': 236,\n",
       "             'interesting': 237,\n",
       "             'music': 238,\n",
       "             'whole': 239,\n",
       "             'almost': 240,\n",
       "             'gets': 241,\n",
       "             'least': 242,\n",
       "             'point': 243,\n",
       "             'done': 244,\n",
       "             'bit': 245,\n",
       "             'script': 246,\n",
       "             'far': 247,\n",
       "             'last': 248,\n",
       "             'minutes': 249,\n",
       "             'feel': 250,\n",
       "             'since': 251,\n",
       "             'might': 252,\n",
       "             'family': 253,\n",
       "             'making': 254,\n",
       "             'anything': 255,\n",
       "             'girl': 256,\n",
       "             'performance': 257,\n",
       "             'am': 258,\n",
       "             'yet': 259,\n",
       "             \"'ll\": 260,\n",
       "             'probably': 261,\n",
       "             'away': 262,\n",
       "             '2': 263,\n",
       "             'tv': 264,\n",
       "             'kind': 265,\n",
       "             'hard': 266,\n",
       "             'fun': 267,\n",
       "             'woman': 268,\n",
       "             'rather': 269,\n",
       "             'worst': 270,\n",
       "             'anyone': 271,\n",
       "             'day': 272,\n",
       "             'sure': 273,\n",
       "             'each': 274,\n",
       "             'found': 275,\n",
       "             'played': 276,\n",
       "             'our': 277,\n",
       "             'screen': 278,\n",
       "             'looking': 279,\n",
       "             'especially': 280,\n",
       "             'having': 281,\n",
       "             'trying': 282,\n",
       "             'believe': 283,\n",
       "             'although': 284,\n",
       "             'course': 285,\n",
       "             'different': 286,\n",
       "             'place': 287,\n",
       "             'set': 288,\n",
       "             'goes': 289,\n",
       "             'dvd': 290,\n",
       "             'ending': 291,\n",
       "             'sense': 292,\n",
       "             'comes': 293,\n",
       "             'worth': 294,\n",
       "             'shows': 295,\n",
       "             'maybe': 296,\n",
       "             'three': 297,\n",
       "             'everything': 298,\n",
       "             'american': 299,\n",
       "             'put': 300,\n",
       "             'once': 301,\n",
       "             'actor': 302,\n",
       "             'let': 303,\n",
       "             'main': 304,\n",
       "             'money': 305,\n",
       "             'effects': 306,\n",
       "             'someone': 307,\n",
       "             'looks': 308,\n",
       "             'book': 309,\n",
       "             'together': 310,\n",
       "             'plays': 311,\n",
       "             'everyone': 312,\n",
       "             'reason': 313,\n",
       "             'true': 314,\n",
       "             'war': 315,\n",
       "             'during': 316,\n",
       "             'play': 317,\n",
       "             'john': 318,\n",
       "             'job': 319,\n",
       "             'instead': 320,\n",
       "             'watched': 321,\n",
       "             \"'d\": 322,\n",
       "             'high': 323,\n",
       "             'said': 324,\n",
       "             'takes': 325,\n",
       "             'special': 326,\n",
       "             'audience': 327,\n",
       "             'seem': 328,\n",
       "             'night': 329,\n",
       "             'later': 330,\n",
       "             'half': 331,\n",
       "             'black': 332,\n",
       "             'himself': 333,\n",
       "             'wife': 334,\n",
       "             'seeing': 335,\n",
       "             'left': 336,\n",
       "             'idea': 337,\n",
       "             'star': 338,\n",
       "             'beautiful': 339,\n",
       "             'death': 340,\n",
       "             'year': 341,\n",
       "             'excellent': 342,\n",
       "             'shot': 343,\n",
       "             'used': 344,\n",
       "             'else': 345,\n",
       "             'house': 346,\n",
       "             'simply': 347,\n",
       "             'second': 348,\n",
       "             'men': 349,\n",
       "             'mind': 350,\n",
       "             'version': 351,\n",
       "             'dead': 352,\n",
       "             'completely': 353,\n",
       "             'budget': 354,\n",
       "             'fan': 355,\n",
       "             'father': 356,\n",
       "             'poor': 357,\n",
       "             'nice': 358,\n",
       "             'less': 359,\n",
       "             'along': 360,\n",
       "             'hollywood': 361,\n",
       "             'short': 362,\n",
       "             'home': 363,\n",
       "             'help': 364,\n",
       "             'boring': 365,\n",
       "             'line': 366,\n",
       "             'women': 367,\n",
       "             'top': 368,\n",
       "             'sex': 369,\n",
       "             'read': 370,\n",
       "             'either': 371,\n",
       "             'try': 372,\n",
       "             '5': 373,\n",
       "             'performances': 374,\n",
       "             'friends': 375,\n",
       "             'camera': 376,\n",
       "             'use': 377,\n",
       "             'kids': 378,\n",
       "             'low': 379,\n",
       "             'wrong': 380,\n",
       "             '3': 381,\n",
       "             'until': 382,\n",
       "             '1': 383,\n",
       "             'couple': 384,\n",
       "             'given': 385,\n",
       "             'next': 386,\n",
       "             'need': 387,\n",
       "             'enjoy': 388,\n",
       "             'production': 389,\n",
       "             'full': 390,\n",
       "             'classic': 391,\n",
       "             'start': 392,\n",
       "             'school': 393,\n",
       "             'stupid': 394,\n",
       "             'truly': 395,\n",
       "             'rest': 396,\n",
       "             'video': 397,\n",
       "             'awful': 398,\n",
       "             '..': 399,\n",
       "             'perhaps': 400,\n",
       "             'mother': 401,\n",
       "             'tell': 402,\n",
       "             'getting': 403,\n",
       "             'moments': 404,\n",
       "             'recommend': 405,\n",
       "             'mean': 406,\n",
       "             'terrible': 407,\n",
       "             'keep': 408,\n",
       "             'understand': 409,\n",
       "             'came': 410,\n",
       "             'face': 411,\n",
       "             'name': 412,\n",
       "             'itself': 413,\n",
       "             'small': 414,\n",
       "             'others': 415,\n",
       "             'playing': 416,\n",
       "             'style': 417,\n",
       "             'boy': 418,\n",
       "             'remember': 419,\n",
       "             'person': 420,\n",
       "             'wonderful': 421,\n",
       "             'doing': 422,\n",
       "             'definitely': 423,\n",
       "             'often': 424,\n",
       "             'human': 425,\n",
       "             'gives': 426,\n",
       "             'dialogue': 427,\n",
       "             'stars': 428,\n",
       "             'perfect': 429,\n",
       "             'lines': 430,\n",
       "             'head': 431,\n",
       "             'written': 432,\n",
       "             'early': 433,\n",
       "             'went': 434,\n",
       "             'lost': 435,\n",
       "             'live': 436,\n",
       "             'entertaining': 437,\n",
       "             'case': 438,\n",
       "             'children': 439,\n",
       "             'title': 440,\n",
       "             'episode': 441,\n",
       "             'hope': 442,\n",
       "             'yes': 443,\n",
       "             'become': 444,\n",
       "             'certainly': 445,\n",
       "             'friend': 446,\n",
       "             'piece': 447,\n",
       "             'liked': 448,\n",
       "             'laugh': 449,\n",
       "             'absolutely': 450,\n",
       "             'based': 451,\n",
       "             'finally': 452,\n",
       "             'picture': 453,\n",
       "             'oh': 454,\n",
       "             'sort': 455,\n",
       "             'several': 456,\n",
       "             'supposed': 457,\n",
       "             'called': 458,\n",
       "             'guys': 459,\n",
       "             'worse': 460,\n",
       "             'problem': 461,\n",
       "             'drama': 462,\n",
       "             'cinema': 463,\n",
       "             'overall': 464,\n",
       "             'entire': 465,\n",
       "             'against': 466,\n",
       "             'fans': 467,\n",
       "             'felt': 468,\n",
       "             'humor': 469,\n",
       "             'direction': 470,\n",
       "             'lead': 471,\n",
       "             'under': 472,\n",
       "             'game': 473,\n",
       "             'waste': 474,\n",
       "             'beginning': 475,\n",
       "             'loved': 476,\n",
       "             'lives': 477,\n",
       "             'dark': 478,\n",
       "             'care': 479,\n",
       "             'son': 480,\n",
       "             'evil': 481,\n",
       "             'totally': 482,\n",
       "             'white': 483,\n",
       "             'seemed': 484,\n",
       "             'despite': 485,\n",
       "             'final': 486,\n",
       "             'wanted': 487,\n",
       "             'killer': 488,\n",
       "             'throughout': 489,\n",
       "             'wo': 490,\n",
       "             'becomes': 491,\n",
       "             'already': 492,\n",
       "             'unfortunately': 493,\n",
       "             'turn': 494,\n",
       "             'guess': 495,\n",
       "             'able': 496,\n",
       "             'sound': 497,\n",
       "             'history': 498,\n",
       "             'days': 499,\n",
       "             'town': 500,\n",
       "             'fine': 501,\n",
       "             'genre': 502,\n",
       "             'quality': 503,\n",
       "             'run': 504,\n",
       "             'heart': 505,\n",
       "             'flick': 506,\n",
       "             'side': 507,\n",
       "             'horrible': 508,\n",
       "             'act': 509,\n",
       "             'today': 510,\n",
       "             'wants': 511,\n",
       "             'example': 512,\n",
       "             'city': 513,\n",
       "             'kill': 514,\n",
       "             'tries': 515,\n",
       "             'close': 516,\n",
       "             'writing': 517,\n",
       "             'past': 518,\n",
       "             'child': 519,\n",
       "             'matter': 520,\n",
       "             'hand': 521,\n",
       "             'viewer': 522,\n",
       "             'turns': 523,\n",
       "             'amazing': 524,\n",
       "             'parts': 525,\n",
       "             'enjoyed': 526,\n",
       "             'car': 527,\n",
       "             'starts': 528,\n",
       "             '\\x96': 529,\n",
       "             'etc': 530,\n",
       "             'themselves': 531,\n",
       "             'killed': 532,\n",
       "             'works': 533,\n",
       "             'expect': 534,\n",
       "             'directed': 535,\n",
       "             'michael': 536,\n",
       "             'stuff': 537,\n",
       "             'behind': 538,\n",
       "             'group': 539,\n",
       "             'favorite': 540,\n",
       "             'gave': 541,\n",
       "             'kid': 542,\n",
       "             'daughter': 543,\n",
       "             'soon': 544,\n",
       "             'brilliant': 545,\n",
       "             'decent': 546,\n",
       "             'eyes': 547,\n",
       "             'stop': 548,\n",
       "             'girls': 549,\n",
       "             'art': 550,\n",
       "             'obviously': 551,\n",
       "             'thinking': 552,\n",
       "             'fight': 553,\n",
       "             'type': 554,\n",
       "             'actress': 555,\n",
       "             'sometimes': 556,\n",
       "             'self': 557,\n",
       "             'blood': 558,\n",
       "             'god': 559,\n",
       "             'known': 560,\n",
       "             'myself': 561,\n",
       "             'late': 562,\n",
       "             'violence': 563,\n",
       "             'hour': 564,\n",
       "             'says': 565,\n",
       "             'highly': 566,\n",
       "             'writer': 567,\n",
       "             'except': 568,\n",
       "             'coming': 569,\n",
       "             'heard': 570,\n",
       "             'took': 571,\n",
       "             'happens': 572,\n",
       "             'stories': 573,\n",
       "             'experience': 574,\n",
       "             'hero': 575,\n",
       "             'feeling': 576,\n",
       "             'extremely': 577,\n",
       "             'voice': 578,\n",
       "             'happened': 579,\n",
       "             'slow': 580,\n",
       "             'police': 581,\n",
       "             'anyway': 582,\n",
       "             'leave': 583,\n",
       "             'moment': 584,\n",
       "             'hell': 585,\n",
       "             'score': 586,\n",
       "             'roles': 587,\n",
       "             'involved': 588,\n",
       "             'murder': 589,\n",
       "             'husband': 590,\n",
       "             'looked': 591,\n",
       "             'living': 592,\n",
       "             'told': 593,\n",
       "             'attempt': 594,\n",
       "             'taken': 595,\n",
       "             'obvious': 596,\n",
       "             'including': 597,\n",
       "             'save': 598,\n",
       "             'strong': 599,\n",
       "             'cool': 600,\n",
       "             'ok': 601,\n",
       "             'wonder': 602,\n",
       "             'mr.': 603,\n",
       "             'david': 604,\n",
       "             'interest': 605,\n",
       "             'happen': 606,\n",
       "             'age': 607,\n",
       "             'hilarious': 608,\n",
       "             'chance': 609,\n",
       "             'robert': 610,\n",
       "             'cut': 611,\n",
       "             'simple': 612,\n",
       "             'brother': 613,\n",
       "             'gore': 614,\n",
       "             'particularly': 615,\n",
       "             'please': 616,\n",
       "             'hit': 617,\n",
       "             'lack': 618,\n",
       "             'across': 619,\n",
       "             'hours': 620,\n",
       "             'complete': 621,\n",
       "             'none': 622,\n",
       "             'ago': 623,\n",
       "             'james': 624,\n",
       "             'career': 625,\n",
       "             'crap': 626,\n",
       "             'serious': 627,\n",
       "             'b': 628,\n",
       "             'exactly': 629,\n",
       "             'reality': 630,\n",
       "             'seriously': 631,\n",
       "             'documentary': 632,\n",
       "             'relationship': 633,\n",
       "             'possible': 634,\n",
       "             'sad': 635,\n",
       "             'annoying': 636,\n",
       "             'power': 637,\n",
       "             'important': 638,\n",
       "             'song': 639,\n",
       "             'shown': 640,\n",
       "             'usually': 641,\n",
       "             'talent': 642,\n",
       "             'running': 643,\n",
       "             'alone': 644,\n",
       "             'light': 645,\n",
       "             'level': 646,\n",
       "             'released': 647,\n",
       "             'female': 648,\n",
       "             'english': 649,\n",
       "             'order': 650,\n",
       "             'opening': 651,\n",
       "             'jokes': 652,\n",
       "             'whose': 653,\n",
       "             'ends': 654,\n",
       "             'taking': 655,\n",
       "             'number': 656,\n",
       "             'call': 657,\n",
       "             'middle': 658,\n",
       "             'wish': 659,\n",
       "             'ridiculous': 660,\n",
       "             'country': 661,\n",
       "             'saying': 662,\n",
       "             'turned': 663,\n",
       "             'cinematography': 664,\n",
       "             'happy': 665,\n",
       "             'scary': 666,\n",
       "             'room': 667,\n",
       "             'yourself': 668,\n",
       "             'view': 669,\n",
       "             'somewhat': 670,\n",
       "             'body': 671,\n",
       "             'silly': 672,\n",
       "             'change': 673,\n",
       "             'four': 674,\n",
       "             'strange': 675,\n",
       "             'mostly': 676,\n",
       "             'huge': 677,\n",
       "             'usual': 678,\n",
       "             'basically': 679,\n",
       "             'finds': 680,\n",
       "             'word': 681,\n",
       "             'started': 682,\n",
       "             'apparently': 683,\n",
       "             'opinion': 684,\n",
       "             'jack': 685,\n",
       "             'attention': 686,\n",
       "             'shots': 687,\n",
       "             'disappointed': 688,\n",
       "             'major': 689,\n",
       "             'words': 690,\n",
       "             'novel': 691,\n",
       "             'beyond': 692,\n",
       "             'single': 693,\n",
       "             'talking': 694,\n",
       "             'miss': 695,\n",
       "             'cheap': 696,\n",
       "             'knew': 697,\n",
       "             'knows': 698,\n",
       "             'thriller': 699,\n",
       "             'non': 700,\n",
       "             'modern': 701,\n",
       "             'sequel': 702,\n",
       "             'clearly': 703,\n",
       "             'ones': 704,\n",
       "             'problems': 705,\n",
       "             'rating': 706,\n",
       "             'due': 707,\n",
       "             'straight': 708,\n",
       "             'french': 709,\n",
       "             '7': 710,\n",
       "             'talk': 711,\n",
       "             'future': 712,\n",
       "             'british': 713,\n",
       "             'upon': 714,\n",
       "             'events': 715,\n",
       "             'sets': 716,\n",
       "             'fast': 717,\n",
       "             'die': 718,\n",
       "             'local': 719,\n",
       "             'tells': 720,\n",
       "             'add': 721,\n",
       "             'television': 722,\n",
       "             'comic': 723,\n",
       "             'parents': 724,\n",
       "             'earth': 725,\n",
       "             'sequence': 726,\n",
       "             'class': 727,\n",
       "             'entertainment': 728,\n",
       "             'ten': 729,\n",
       "             'above': 730,\n",
       "             'bring': 731,\n",
       "             'king': 732,\n",
       "             'dialog': 733,\n",
       "             'team': 734,\n",
       "             'hate': 735,\n",
       "             'easily': 736,\n",
       "             'review': 737,\n",
       "             'george': 738,\n",
       "             'clear': 739,\n",
       "             'predictable': 740,\n",
       "             'giving': 741,\n",
       "             'musical': 742,\n",
       "             'appears': 743,\n",
       "             'lots': 744,\n",
       "             'within': 745,\n",
       "             'near': 746,\n",
       "             'similar': 747,\n",
       "             'five': 748,\n",
       "             '8': 749,\n",
       "             'romantic': 750,\n",
       "             'easy': 751,\n",
       "             'falls': 752,\n",
       "             'filmed': 753,\n",
       "             'storyline': 754,\n",
       "             'enjoyable': 755,\n",
       "             'bunch': 756,\n",
       "             'supporting': 757,\n",
       "             'space': 758,\n",
       "             'ways': 759,\n",
       "             'mention': 760,\n",
       "             'typical': 761,\n",
       "             'certain': 762,\n",
       "             'episodes': 763,\n",
       "             'working': 764,\n",
       "             'message': 765,\n",
       "             'named': 766,\n",
       "             'moving': 767,\n",
       "             'whether': 768,\n",
       "             'eye': 769,\n",
       "             'release': 770,\n",
       "             'general': 771,\n",
       "             'sorry': 772,\n",
       "             'stand': 773,\n",
       "             'mystery': 774,\n",
       "             'surprised': 775,\n",
       "             'crime': 776,\n",
       "             'theme': 777,\n",
       "             'dull': 778,\n",
       "             'songs': 779,\n",
       "             'elements': 780,\n",
       "             'avoid': 781,\n",
       "             'soundtrack': 782,\n",
       "             'among': 783,\n",
       "             'monster': 784,\n",
       "             'fall': 785,\n",
       "             'tale': 786,\n",
       "             'gone': 787,\n",
       "             'suspense': 788,\n",
       "             'stay': 789,\n",
       "             'york': 790,\n",
       "             'tried': 791,\n",
       "             'needs': 792,\n",
       "             'gay': 793,\n",
       "             'begins': 794,\n",
       "             'effort': 795,\n",
       "             'showing': 796,\n",
       "             'using': 797,\n",
       "             'kept': 798,\n",
       "             'viewers': 799,\n",
       "             'america': 800,\n",
       "             'points': 801,\n",
       "             'comments': 802,\n",
       "             'richard': 803,\n",
       "             'theater': 804,\n",
       "             'red': 805,\n",
       "             'feels': 806,\n",
       "             'dog': 807,\n",
       "             'sister': 808,\n",
       "             'buy': 809,\n",
       "             'doubt': 810,\n",
       "             'means': 811,\n",
       "             'tom': 812,\n",
       "             'peter': 813,\n",
       "             'leads': 814,\n",
       "             'okay': 815,\n",
       "             'nearly': 816,\n",
       "             'feature': 817,\n",
       "             'viewing': 818,\n",
       "             'brought': 819,\n",
       "             'herself': 820,\n",
       "             'editing': 821,\n",
       "             'rent': 822,\n",
       "             'period': 823,\n",
       "             'deal': 824,\n",
       "             'killing': 825,\n",
       "             'realistic': 826,\n",
       "             'de': 827,\n",
       "             'somehow': 828,\n",
       "             'truth': 829,\n",
       "             'lady': 830,\n",
       "             'fantastic': 831,\n",
       "             'imagine': 832,\n",
       "             'form': 833,\n",
       "             'check': 834,\n",
       "             'follow': 835,\n",
       "             'famous': 836,\n",
       "             'sequences': 837,\n",
       "             'material': 838,\n",
       "             'fi': 839,\n",
       "             'move': 840,\n",
       "             'believable': 841,\n",
       "             'average': 842,\n",
       "             's': 843,\n",
       "             'third': 844,\n",
       "             'forget': 845,\n",
       "             '9': 846,\n",
       "             'reviews': 847,\n",
       "             'sci': 848,\n",
       "             'surprise': 849,\n",
       "             'paul': 850,\n",
       "             'rock': 851,\n",
       "             'deep': 852,\n",
       "             'cop': 853,\n",
       "             'greatest': 854,\n",
       "             'premise': 855,\n",
       "             'whatever': 856,\n",
       "             'figure': 857,\n",
       "             'subject': 858,\n",
       "             'lee': 859,\n",
       "             'oscar': 860,\n",
       "             're': 861,\n",
       "             'expected': 862,\n",
       "             'poorly': 863,\n",
       "             'actual': 864,\n",
       "             'indeed': 865,\n",
       "             'open': 866,\n",
       "             'weak': 867,\n",
       "             'hear': 868,\n",
       "             'learn': 869,\n",
       "             'free': 870,\n",
       "             'eventually': 871,\n",
       "             'lame': 872,\n",
       "             'sit': 873,\n",
       "             'minute': 874,\n",
       "             'society': 875,\n",
       "             'crew': 876,\n",
       "             'forced': 877,\n",
       "             'western': 878,\n",
       "             'atmosphere': 879,\n",
       "             'possibly': 880,\n",
       "             'animation': 881,\n",
       "             'note': 882,\n",
       "             'box': 883,\n",
       "             'wait': 884,\n",
       "             'situation': 885,\n",
       "             '6': 886,\n",
       "             'difficult': 887,\n",
       "             'sexual': 888,\n",
       "             'leaves': 889,\n",
       "             'otherwise': 890,\n",
       "             'romance': 891,\n",
       "             'decided': 892,\n",
       "             'hot': 893,\n",
       "             '20': 894,\n",
       "             'begin': 895,\n",
       "             'question': 896,\n",
       "             'particular': 897,\n",
       "             '$': 898,\n",
       "             'reading': 899,\n",
       "             'boys': 900,\n",
       "             'stage': 901,\n",
       "             'acted': 902,\n",
       "             'male': 903,\n",
       "             'plus': 904,\n",
       "             'became': 905,\n",
       "             'shame': 906,\n",
       "             'footage': 907,\n",
       "             'screenplay': 908,\n",
       "             'interested': 909,\n",
       "             'personal': 910,\n",
       "             'cheesy': 911,\n",
       "             'meet': 912,\n",
       "             'credits': 913,\n",
       "             'towards': 914,\n",
       "             'memorable': 915,\n",
       "             'previous': 916,\n",
       "             'air': 917,\n",
       "             'doctor': 918,\n",
       "             'nor': 919,\n",
       "             'gun': 920,\n",
       "             'earlier': 921,\n",
       "             'effect': 922,\n",
       "             'battle': 923,\n",
       "             'street': 924,\n",
       "             'island': 925,\n",
       "             'needed': 926,\n",
       "             'features': 927,\n",
       "             'unless': 928,\n",
       "             'hands': 929,\n",
       "             'perfectly': 930,\n",
       "             'joe': 931,\n",
       "             'emotional': 932,\n",
       "             'worked': 933,\n",
       "             'whom': 934,\n",
       "             'powerful': 935,\n",
       "             'laughs': 936,\n",
       "             'result': 937,\n",
       "             'business': 938,\n",
       "             'quickly': 939,\n",
       "             'imdb': 940,\n",
       "             'mess': 941,\n",
       "             'writers': 942,\n",
       "             'setting': 943,\n",
       "             'total': 944,\n",
       "             'keeps': 945,\n",
       "             'write': 946,\n",
       "             'season': 947,\n",
       "             'background': 948,\n",
       "             'forward': 949,\n",
       "             'badly': 950,\n",
       "             'comment': 951,\n",
       "             'crazy': 952,\n",
       "             'older': 953,\n",
       "             'nature': 954,\n",
       "             'dance': 955,\n",
       "             'dramatic': 956,\n",
       "             'masterpiece': 957,\n",
       "             'superb': 958,\n",
       "             'mark': 959,\n",
       "             'girlfriend': 960,\n",
       "             'meets': 961,\n",
       "             'bill': 962,\n",
       "             'pay': 963,\n",
       "             'era': 964,\n",
       "             'various': 965,\n",
       "             'rich': 966,\n",
       "             'baby': 967,\n",
       "             'appear': 968,\n",
       "             'realize': 969,\n",
       "             'weird': 970,\n",
       "             'directing': 971,\n",
       "             'unique': 972,\n",
       "             'sounds': 973,\n",
       "             'inside': 974,\n",
       "             'japanese': 975,\n",
       "             'front': 976,\n",
       "             'brothers': 977,\n",
       "             'development': 978,\n",
       "             'present': 979,\n",
       "             'incredibly': 980,\n",
       "             'telling': 981,\n",
       "             'beauty': 982,\n",
       "             'plenty': 983,\n",
       "             'twist': 984,\n",
       "             'party': 985,\n",
       "             'fairly': 986,\n",
       "             'brings': 987,\n",
       "             'copy': 988,\n",
       "             'william': 989,\n",
       "             'fighting': 990,\n",
       "             'directors': 991,\n",
       "             'apart': 992,\n",
       "             'outside': 993,\n",
       "             'break': 994,\n",
       "             'secret': 995,\n",
       "             'dumb': 996,\n",
       "             'rate': 997,\n",
       "             'water': 998,\n",
       "             'reasons': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine parameters for uint8\n",
      "---------------------------------------------------------------\n",
      "min = 0\n",
      "max = 255\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Machine parameters for uint16\n",
      "---------------------------------------------------------------\n",
      "min = 0\n",
      "max = 65535\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Machine parameters for uint32\n",
      "---------------------------------------------------------------\n",
      "min = 0\n",
      "max = 4294967295\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.iinfo(np.uint8))\n",
    "print(np.iinfo(np.uint16))\n",
    "print(np.iinfo(np.uint32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    2,     7,     8,  1090,    14,   114,    19,  6434,  7502,\n",
       "         104,    12,    29,    25,   247,   146,   217,    60,    93,\n",
       "         102,  1190,   704,     9,     7,     8,   469,   588,    17,\n",
       "           8,   123,    15,    37,  9268,   469,    10,    11,    15,\n",
       "         103,   123,  2085,   214,    14,    42,  5656,    60,    28,\n",
       "          48,   564,    55,   127,     9,    24,     7,  3051,   214,\n",
       "           8,   888,  1533,   484,    53,    16,    96,    42,  4594,\n",
       "          10,    30,    20,   227,    41,    99,   107,     8,  9463,\n",
       "          13,   436,   722, 28287,    89,    14,    37,   534,    16,\n",
       "           9,    18,  1370,    18,    25,   552,    69,    21,     7,\n",
       "       16700,     7,  2009,     7,  2562,    21, 14208,    93,     8,\n",
       "        1121,    86,    92,    24,     7,   423,    37,    12,  5336,\n",
       "          29,    10,    80,   105,   261,  1515,    16,    51,   144,\n",
       "        5075,     8,  5684,    13,   112,    69,  1152,  8486,    10,\n",
       "          30,   152,   146,   855,    11,   517,    93,   112,    69,\n",
       "        6390,   704,     9,    24,    18,   448,    16,    10,    30,\n",
       "          18,   810,    16,   105,    42,    12,  6699,   617,    92,\n",
       "          36,    80,    15,   635,    10,    26,     7,  1903,     7,\n",
       "       11561,  4661,    37,    14,    58,   121,    20,  8487,    89,\n",
       "          27,   205,     8, 12983,   102,  6434, 21808,  2482,    14,\n",
       "          33,     3], dtype=uint16)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numericalize(list_of_tokens):\n",
    "    return np.array([otoi[tok] for tok in list_of_tokens], dtype=np.uint16)\n",
    "\n",
    "def denumericalize(list_of_nums):\n",
    "    return [vocab[i] for i in list_of_nums]\n",
    "\n",
    "toks = tokenize(read_file(filenames[0]))\n",
    "assert toks == denumericalize(numericalize(toks))\n",
    "numericalize(toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess texts in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro_dir = pathlib.Path(\"../../Datasets/NLP/IMBd_prepro\")\n",
    "\n",
    "def preprocess_text(input_file_path):\n",
    "    file_name   = input_file_path.name[:-4]       # filename without \".txt\"\n",
    "    class_name  = input_file_path.parents[0].name # pos or neg\n",
    "    subset_name = input_file_path.parents[1].name # train, test or unsup\n",
    "    folder      = prepro_dir / subset_name / class_name\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    text_string = read_file(input_file_path) # 1. Read text file\n",
    "    text_tokens = tokenize(text_string)      # 2. Tokenize text\n",
    "    text_nums   = numericalize(text_tokens)  # 3. Numerizalize tokens (uint16)\n",
    "    np.save(folder/file_name, text_nums)     # 4. Save numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70eaf706ad5942d2a8f950fdf7907b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = parallel_map(func=preprocess_text, array=filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
