<h1 align="center">Neural Networks</h1>


# TODO
- Parameters and activations
- Random initialization and transfer learning
- SGD, Momentum, Adam, and other optimizers
- Convolutions
- Batch normalization
- Dropout y DropConnect
- Data augmentation
- Label smoothing
- Weight decay
- Entity embeddings
- Recurrent neural networks (RNNs)
- Segmentation
- Collaborative filtering (ej. movie recommendation)
- [arbitrary order (>=2) Factorization Machine](https://github.com/geffy/tffm)

### Neural Network

Take the longest time to train, and require extra preprocessing such as normalisation; this normalisation needs to be used at inference time as well. They can provide great results, and extrapolate well, but only if you are careful with your hyperparameters, and are careful to avoid overfitting.

<p align="center"><img width="80%" src="img/NeuralNet.png" /></p>




# Model


# Loss


# Train Hyperparms
