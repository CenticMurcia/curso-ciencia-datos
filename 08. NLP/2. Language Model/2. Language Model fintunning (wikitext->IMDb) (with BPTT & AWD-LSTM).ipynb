{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: We need preprocessed texts (tokinized and numericalized) in this notebook\n",
    "\n",
    "> Notebook based on:\n",
    "> 1. https://github.com/fastai/course-v3/blob/master/nbs/dl2/12_text.ipynb\n",
    "> 2. https://github.com/fastai/course-v3/blob/master/nbs/dl2/12a_awd_lstm.ipynb\n",
    "> 3. https://github.com/fastai/course-v3/blob/master/nbs/dl2/12b_lm_pretrain.ipynb\n",
    "> 4. https://github.com/fastai/course-v3/blob/master/nbs/dl2/12c_ulmfit.ipynb\n",
    "> \n",
    "> Video:\n",
    "> - https://youtu.be/vnOpEwmtFJ8?t=4687 from 1:18:00 to 2:08:00 (50 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BPTT_LEN   = 70 # Lengh of the minisequences in the big stream (used In Dataset)\n",
    "BATCH_SIZE = 64 # (used In DataLoader)\n",
    "UNK_TOKEN  = 0  # Number for xxunk token (used in numericalization)\n",
    "PAD_TOKEN  = 1  # Number for xxPad token (used in the nn.Embedding layer of the Model)\n",
    "VOCAB_LEN  = None # This will be updated when we read the vocab.pkl file (used in the nn.Embedding layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch: 1.8.1\n",
      "Fast.ai: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader\n",
    "\n",
    "import fastai\n",
    "print(\"Pytorch:\", torch.__version__)\n",
    "print(\"Fast.ai:\", fastai.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  train  unsup  vocab.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"../../Datasets/NLP/IMBd_prepro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg  pos\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"../../Datasets/NLP/IMBd_prepro/train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = open(\"../../Datasets/NLP/IMBd_prepro/vocab.pkl\",'rb')\n",
    "imdb_vocab = pickle.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65539"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_LEN = len(imdb_vocab)\n",
    "VOCAB_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(word):\n",
    "    try:    return imdb_vocab.index(word)\n",
    "    except: return UNK_TOKEN\n",
    "    \n",
    "def denumericalize(num):\n",
    "    return imdb_vocab[num]\n",
    "\n",
    "def numericalize_list(words):\n",
    "    return [numericalize(word) for word in words]\n",
    "\n",
    "def denumericalize_list(nums):\n",
    "    return [denumericalize(num) for num in nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5255, 195, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericalize_list( [\"hello\", \"world\", \"this_is_unknown_token\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'xxup',\n",
       " 'xxmaj',\n",
       " 'the',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denumericalize_list( range(10) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def parallel_map(func, array):\n",
    "    \n",
    "    cpu_cores = multiprocessing.cpu_count()\n",
    "    array_len = len(array)\n",
    "    chunksize = array_len // 100\n",
    "    \n",
    "    if cpu_cores<2:\n",
    "        return list(tqdm(map(func, arr), total=array_len))\n",
    "    else:\n",
    "        with ProcessPoolExecutor(max_workers=cpu_cores) as ex:\n",
    "            return list(tqdm(ex.map(func, array, chunksize=chunksize), total=array_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <center> Dataset & Dataloader for Langauge Model\n",
    "- X: Text\n",
    "- Y: Same text but shifted by 1 token\n",
    "\n",
    "At every epoch:\n",
    "\n",
    "1. **Shuffle** (sort randomly) our collection of texts.\n",
    "2. **Concatenate** the individual texts together into a big stream. \n",
    "3. **Cut** this stream into a certain number of batches (which is our batch size).\n",
    "   - For instance, if the stream has 50,000 tokens and we set a batch size of 10, this will give us 10 mini-streams of 5,000 tokens.\n",
    "   \n",
    "So to recap, at every epoch we shuffle our collection of documents and concatenate them into a stream of tokens. We then cut that stream into a batch of fixed-size consecutive mini-streams. Our model will then read the mini-streams in order, and thanks to an inner state, it will produce the same activation whatever sequence length we picked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, prepro_texts_dir, bptt=70, shuffle=False):\n",
    "        \n",
    "        # Read tokenized and numeralized text files (numpy format)\n",
    "        np_filepaths = list( pathlib.Path(prepro_texts_dir).glob('**/*.npy') ) \n",
    "        \n",
    "        # Open numpy arrays in parallel\n",
    "        #self.texts_np = list(map(func=np.load, np_filepaths))  # Non parallel version   \n",
    "        self.texts_np = parallel_map(func=np.load, array=np_filepaths)\n",
    "\n",
    "        self.bptt    = bptt\n",
    "        self.shuffle = shuffle\n",
    "        self.total_tokens = sum([len(t) for t in self.texts_np])\n",
    "        \n",
    "        self.concat_texts_into_stream()\n",
    "        \n",
    "    # this is necesseary at the begining of every epoch for train !!!!\n",
    "    def concat_texts_into_stream(self):\n",
    "        \n",
    "        # 1. Reorder texts if we need to\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.texts_np)\n",
    "            #self.texts_np = self.texts_np[np.random.permutation(len(self.texts_np))]\n",
    "            \n",
    "        # 2. Concat texts into a large stream\n",
    "        self.stream = np.concatenate(self.texts_np)\n",
    "        #self.stream = torch.cat([torch.Tensor(t) for t in self.texts_np])\n",
    "                \n",
    "    def __len__(self):\n",
    "        return self.total_tokens // self.bptt\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.stream[idx   : idx+self.bptt]\n",
    "        y = self.stream[idx+1 : idx+self.bptt+1] # shifted by 1\n",
    "        \n",
    "        # convert from numpy.uint16 to torch.int64        \n",
    "        x = torch.tensor(x.astype(\"int64\"))\n",
    "        y = torch.tensor(y.astype(\"int64\"))\n",
    "        \n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2dac73b7bff490aa59d2c70830ad72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585307ecf2f744c59e135f964995a260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = LM_Dataset(\"../../Datasets/NLP/IMBd_prepro/train\", bptt=BPTT_LEN, shuffle=True)\n",
    "valid_ds = LM_Dataset(\"../../Datasets/NLP/IMBd_prepro/test\",  bptt=BPTT_LEN, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    7,    83,    97,   343,    34,   397,    21,    31,    21,   113,\n",
       "            47,    37,    43,    10,    37,   127,    10,    30,   297,  2506,\n",
       "           397,  1202,     9,    24,     7,    63,    32,   200,   182,    14,\n",
       "           114,    12,    97,   201,    31,    45,   242,  1385,    17,    65,\n",
       "           558,    10,   614,    11,  1040,     9,     7,    54,    15,    65,\n",
       "           558,  2244,    47, 17823,   611,   141,  3083,  3887,  1263,    45,\n",
       "            12,     7,  2403,  1060,     9,     7,    54,    38,  7015,    11]),\n",
       " tensor([   83,    97,   343,    34,   397,    21,    31,    21,   113,    47,\n",
       "            37,    43,    10,    37,   127,    10,    30,   297,  2506,   397,\n",
       "          1202,     9,    24,     7,    63,    32,   200,   182,    14,   114,\n",
       "            12,    97,   201,    31,    45,   242,  1385,    17,    65,   558,\n",
       "            10,   614,    11,  1040,     9,     7,    54,    15,    65,   558,\n",
       "          2244,    47, 17823,   611,   141,  3083,  3887,  1263,    45,    12,\n",
       "             7,  2403,  1060,     9,     7,    54,    38,  7015,    11, 11470]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('xxbos xxmaj really bad shot on video \" film \" made by not one , not two , but three amateur video makers . \\n\\n xxmaj if you \\'re going to make a bad horror film at least throw in some blood , gore and nudity . xxmaj there is some blood provided by latex cut off arm props bought at a xxmaj halloween store . xxmaj there are lesbians',\n",
       " 'xxmaj really bad shot on video \" film \" made by not one , not two , but three amateur video makers . \\n\\n xxmaj if you \\'re going to make a bad horror film at least throw in some blood , gore and nudity . xxmaj there is some blood provided by latex cut off arm props bought at a xxmaj halloween store . xxmaj there are lesbians and')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(denumericalize(train_ds[0][0])), \" \".join(denumericalize(train_ds[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader (with custom sampler for BPTT)\n",
    "\n",
    "if we divide our big stream of **28 elements** with **batch_size of 5**:\n",
    "\n",
    "|               |              |               |               |               |               |\n",
    "|---------------|--------------|---------------|---------------|---------------|---------------|\n",
    "| **1st batch** | stream_idx 0 | stream_idx 6  | stream_idx 12 | stream_idx 18 | stream_idx 23 |\n",
    "| **2nd batch** | stream_idx 1 | stream_idx 7  | stream_idx 13 | stream_idx 19 | stream_idx 24 |\n",
    "| **3rd batch** | stream_idx 2 | stream_idx 8  | stream_idx 14 | stream_idx 20 | stream_idx 25 |\n",
    "| **4th batch** | stream_idx 3 | stream_idx 8  | stream_idx 15 | stream_idx 21 | stream_idx 26 |\n",
    "| **5th batch** | stream_idx 4 | stream_idx 10 | stream_idx 16 | stream_idx 22 | stream_idx 27 |\n",
    "| **6th batch** | stream_idx 5 | stream_idx 11 | stream_idx 17 |               |               |\n",
    "\n",
    "https://pytorchnlp.readthedocs.io/en/latest/_modules/torchnlp/samplers/bptt_sampler.html\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPTT_BatchSampler(Sampler):\n",
    "    def __init__(self, n_elements, batch_size, drop_last):\n",
    "        \n",
    "        indexes = np.array_split(list(range(n_elements)), batch_size) # magic happens here\n",
    "        \n",
    "        n_batches = n_elements//batch_size\n",
    "        self.batches_idxs = np.array([x[:n_batches] for x in indexes]).T.tolist()\n",
    "        \n",
    "        if not drop_last:\n",
    "            last_batch_idxs = np.array([x[n_batches:] for x in indexes if x[n_batches:].size==1]).T.tolist()\n",
    "            self.batches_idxs += last_batch_idxs\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return iter(self.batches_idxs)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.batches_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,\n",
       " [[0, 6, 12, 18, 23],\n",
       "  [1, 7, 13, 19, 24],\n",
       "  [2, 8, 14, 20, 25],\n",
       "  [3, 9, 15, 21, 26],\n",
       "  [4, 10, 16, 22, 27],\n",
       "  [5, 11, 17]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = BPTT_BatchSampler(n_elements=28, batch_size=5, drop_last=False)\n",
    "len(s), list(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " [[0, 6, 12, 18, 23],\n",
       "  [1, 7, 13, 19, 24],\n",
       "  [2, 8, 14, 20, 25],\n",
       "  [3, 9, 15, 21, 26],\n",
       "  [4, 10, 16, 22, 27]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = BPTT_BatchSampler(n_elements=28, batch_size=5, drop_last=True)\n",
    "len(s), list(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 70]), torch.Size([64, 70]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DataLoader(train_ds, batch_sampler=BPTT_BatchSampler(n_elements=len(train_ds),\n",
    "                                                                batch_size=BATCH_SIZE,\n",
    "                                                                drop_last=True))\n",
    "\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=BPTT_BatchSampler(n_elements=len(valid_ds),\n",
    "                                                                batch_size=BATCH_SIZE,\n",
    "                                                                drop_last=True))\n",
    "\n",
    "batch_x, batch_y = next(iter(train_dl))\n",
    "batch_x.shape, batch_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: Pretrained LSTM from wikitext103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model layer structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(60000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_language_model(arch=AWD_LSTM, vocab_sz=60000 )\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put wikipedia pretrained weights into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/javi/.fastai/data/wt103-fwd')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = untar_data(URLs.WT103_FWD)\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_vocab_filepath  = model_path / \"itos_wt103.pkl\"\n",
    "wikipedia_weights_filepath = model_path / \"lstm_fwd.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open_file(wikipedia_vocab_filepath, 'rb') as file:\n",
    "    wikipedia_vocab = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wikipedia_weights = torch.load(wikipedia_weights_filepath, map_location = lambda storage,loc: storage)\n",
    "wikipedia_weights = clean_raw_keys(wikipedia_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(wikipedia_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put new words (of IMDb) in the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki vocab: 60000\n",
      "imdb vocab: 65539\n",
      "---------------------\n",
      "wiki only vocab: 22951\n",
      "imdb only vocab: 28490 (43.47% of imdb)\n",
      "in common vocab: 37049 (56.53% of imdb)\n"
     ]
    }
   ],
   "source": [
    "wiki_only_vocab = len(set(wikipedia_vocab) - set(imdb_vocab))\n",
    "imdb_only_vocab = len(set(imdb_vocab) - set(wikipedia_vocab))\n",
    "in_common_vocab = len(set(imdb_vocab) & set(wikipedia_vocab))\n",
    "\n",
    "print(\"wiki vocab:\", len(wikipedia_vocab))\n",
    "print(\"imdb vocab:\", len(imdb_vocab))\n",
    "print(\"---------------------\")\n",
    "print(f\"wiki only vocab: {wiki_only_vocab}\")\n",
    "print(f\"imdb only vocab: {imdb_only_vocab} ({round(imdb_only_vocab/len(imdb_vocab)*100,2)}% of imdb)\")\n",
    "print(f\"in common vocab: {in_common_vocab} ({round(in_common_vocab/len(imdb_vocab)*100,2)}% of imdb)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 400])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1276,  0.0161,  0.1617,  ..., -0.1396,  0.6899, -0.0399],\n",
       "        [ 0.0272,  0.0011,  0.0401,  ...,  0.0161,  0.0666, -0.0014],\n",
       "        [ 0.6069, -0.5239,  0.1544,  ..., -0.2551, -0.3308, -0.0702],\n",
       "        ...,\n",
       "        [ 0.0096,  0.0814,  0.0213,  ...,  0.0712,  0.0810, -0.0045],\n",
       "        [ 0.0283, -0.0176,  0.0361,  ...,  0.0756,  0.1470, -0.0139],\n",
       "        [ 0.1267, -0.0656,  0.0362,  ..., -0.0191,  0.0673,  0.0154]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_emb_matrix = model[0].encoder.weight.data\n",
    "print(old_emb_matrix.shape)\n",
    "old_emb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16469064250a483fa2693663d6728302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_emb_matrix = torch.zeros( (len(imdb_vocab), old_emb_matrix.size(1)) )\n",
    "old_emb_matrix_mean = old_emb_matrix.mean(0)\n",
    "\n",
    "for i,word in tqdm(enumerate(imdb_vocab), total=len(imdb_vocab)):\n",
    "    \n",
    "    try:\n",
    "        # If the word exits on the wikipedia vocab -> Use existing embedding\n",
    "        old_emb_idx = wikipedia_vocab.index(word)\n",
    "        new_emb_matrix[i] = old_emb_matrix[old_emb_idx]\n",
    "    except:\n",
    "        # If the word is new -> Use default embedding (the mean)\n",
    "        new_emb_matrix[i] = old_emb_matrix_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65539, 400])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1276,  0.0161,  0.1617,  ..., -0.1396,  0.6899, -0.0399],\n",
       "        [ 0.0272,  0.0011,  0.0401,  ...,  0.0161,  0.0666, -0.0014],\n",
       "        [ 0.6069, -0.5239,  0.1544,  ..., -0.2551, -0.3308, -0.0702],\n",
       "        ...,\n",
       "        [-0.1464,  0.0314,  0.1414,  ..., -0.1256,  0.2263, -0.2686],\n",
       "        [ 0.0253,  0.0026,  0.0423,  ...,  0.0128,  0.0848, -0.0018],\n",
       "        [ 0.0253,  0.0026,  0.0423,  ...,  0.0128,  0.0848, -0.0018]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(new_emb_matrix.shape)\n",
    "new_emb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0].encoder = nn.Embedding(num_embeddings = new_emb_matrix.shape[0],\n",
    "                                embedding_dim  = new_emb_matrix.shape[1],\n",
    "                                padding_idx    = 1,\n",
    "                                _weight        = new_emb_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0].encoder_dp.emb = nn.Embedding(num_embeddings = new_emb_matrix.shape[0],\n",
    "                                embedding_dim  = new_emb_matrix.shape[1],\n",
    "                                padding_idx    = 1,\n",
    "                                _weight        = new_emb_matrix)\n",
    "\n",
    "model[0].encoder_dp.emb.weight = model[0].encoder.weight # Weight tiying !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[1].decoder = nn.Linear(in_features  = new_emb_matrix.shape[1],\n",
    "                             out_features = new_emb_matrix.shape[0],\n",
    "                             bias = True)\n",
    "\n",
    "model[1].decoder.weight = model[0].encoder.weight # Weight tiying !!\n",
    "model[1].decoder.bias.data.zero_();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(65539, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(65539, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=65539, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model\n",
    "We return three things:\n",
    "1. The true output (probabilities for each word),\n",
    "2. The activations of the encoder with dropouts. (to help with regularization)\n",
    "3. The activations of the encoder without dropouts. to help with regularization\n",
    "\n",
    "Becouse of this, we need to use the [RNNCallback](https://docs.fast.ai/callback.rnn.html#RNNCallback) to only keep the true output for loss computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 70, 65539]),\n",
       " torch.Size([64, 70, 400]),\n",
       " torch.Size([64, 70, 400]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_p, hid1, hid1 = model(batch_x) # prediction and something else\n",
    "batch_p.shape, hid1.shape, hid1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss: Flat CrossEntropy\n",
    "\n",
    "Custom CrossEntropyLossFlat inspired by [Fast.ai CrossEntropyLossFlat()](https://docs.fast.ai/losses.html#CrossEntropyLossFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred:   torch.Size([64, 70, 65539])\n",
      "Target: torch.Size([64, 70])\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred:  \", batch_p.shape)\n",
    "print(\"Target:\", batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred:   torch.Size([4480, 65539])\n",
      "Target: torch.Size([4480])\n"
     ]
    }
   ],
   "source": [
    "batch_p_flatten = batch_p.view(-1, batch_p.shape[-1])\n",
    "batch_y_flatten = batch_y.view(-1)\n",
    "\n",
    "print(\"Pred:  \", batch_p_flatten.shape)\n",
    "print(\"Target:\", batch_y_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLossFlat(nn.Module):\n",
    "    \"\"\"Flatten version of nn.CrossEntropyLoss()\"\"\"\n",
    "    def forward(self, pred, target):\n",
    "        pred_flatten   = pred.view(-1, pred.shape[-1])\n",
    "        target_flatten = target.view(-1)\n",
    "        return F.cross_entropy(pred_flatten, target_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.3656, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "ce_loss(batch_p_flatten, batch_y_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.3656, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_flat_loss = CrossEntropyLossFlat()\n",
    "ce_flat_loss(batch_p, batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Fast.ai: 2.3.1\n",
    "from fastai.learner           import Learner\n",
    "from fastai.data.core         import DataLoaders\n",
    "from fastai.metrics           import accuracy, Perplexity\n",
    "\n",
    "from fastai.callback.all      import * # For lr_find() and fit_one_cycle()\n",
    "from fastai.callback.core     import Callback\n",
    "from fastai.callback.progress import ProgressCallback, ShowGraphCallback\n",
    "from fastai.callback.training import GradientClip\n",
    "from fastai.callback.rnn      import ModelResetter, RNNCallback, RNNRegularizer\n",
    "from fastai.callback.tracker  import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowGraphEveryBatchCallback(Callback):\n",
    "    \"Update a graph of training and validation loss\"\n",
    "        \n",
    "    def after_batch(self):\n",
    "        if self.iter%15 == 0:\n",
    "            rec   = self.learn.recorder\n",
    "            iters = range(len(rec.losses))\n",
    "            x_bounds = (0, self.n_epoch * self.n_iter)\n",
    "            y_bounds = (0, 10)\n",
    "            self.progress.mbar.update_graph([(iters, rec.losses)], x_bounds, y_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls       = DataLoaders(train_dl, valid_dl),\n",
    "                model     = model, \n",
    "                loss_func = CrossEntropyLossFlat(),\n",
    "                metrics   = [accuracy, Perplexity],\n",
    "                cbs       = [\n",
    "                          #  TrainEvalCallback, # By default\n",
    "                          #  Recorder,          # By default\n",
    "                          #  ProgressCallback,  # By default\n",
    "                             ModelResetter,\n",
    "                             RNNCallback,\n",
    "                             RNNRegularizer,\n",
    "                             ShowGraphEveryBatchCallback,\n",
    "                             GradientClip(max_norm=0.1),\n",
    "                          #  TensorBoardCallback(\"/home/javi/Escritorio/tensorboard\", trace_model=True)\n",
    "                          #  partial(AvgStatsCallback,accuracy_flat),\n",
    "                          #  Recorder,  #     Registers statistics (lr, loss and metrics) during training\n",
    "                          #  partial(GradientClipping, clip=0.1),\n",
    "                          #  partial(RNNTrainer, α=2., β=1.),\n",
    "                          #  ParamScheduler({'lr': SchedLin(1e-3, 1e-2)})\n",
    "                          #  EarlyStoppingCallback(patience=3)\n",
    "                          #  SaveModelCallback()\n",
    "                            ])\n",
    "#learn.show_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.lr_find()\n",
    "#fig = learn.recorder.plot(suggestion=True, return_fig=True);\n",
    "#lr  = learn.recorder.min_grad_lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.992864</td>\n",
       "      <td>5.868248</td>\n",
       "      <td>0.197092</td>\n",
       "      <td>353.628693</td>\n",
       "      <td>09:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1, 1e-3) # learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|experiment |epochs| lr        |train_loss | valid_loss |accuracy  | perplexity |time | notes                 |\n",
    "|-----------|------|-----------|-----------|------------|----------|------------|-----|:---------------------:|\n",
    "|     a     |  1   |           | 19.061800 | 45.006886  | 0.090237 |     -      |09:10|          -            |\n",
    "|     b     |  1   |           | 5.943309  | 7.154285   | 0.090238 |1279.577148 |09:38| only predicts `xxmaj` |\n",
    "|     c     |  1   |Const 1e-3 | 1.992864  | 5.868248   | 0.197092 | 353.628693 |09:18|                       |\n",
    "\n",
    "Objetive (in 10 epochs) [video](https://youtu.be/vnOpEwmtFJ8?t=7549): train_loss=4.03 valid_loss=**4.06** valid_accuracy=**0.2867**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_p,_,_= learn.model(batch_x.cuda())\n",
    "#batch_p = batch_p.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase(0.7792, device='cuda:0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(batch_p, batch_y.cuda()) # On some train batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   7,   54,  357,  ...,   38, 1551,   10],\n",
       "        [  12,  429,   20,  ...,   12,   14,   40],\n",
       "        [  13,   59,    8,  ...,   18,  217,   63],\n",
       "        ...,\n",
       "        [  10,    8, 2148,  ...,    8,   30,   10],\n",
       "        [ 166,  435,   26,  ...,   73,   21,    8],\n",
       "        [  10,   30, 2234,  ...,   10,  191,  268]], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = batch_p.argmax(dim=-1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    0,     2,     3,  ..., 56009, 56717, 65100], device='cuda:0'),\n",
       " tensor([17, 12, 12,  ...,  1,  1,  1], device='cuda:0'))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(learn.model.state_dict(), './language_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
